{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "42b5e80b-ad1d-4335-a1f7-10a91127e3dc"
    }
   },
   "source": [
    "# Train and Deploy (Based on lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "Dataset loaded successfully. Shape: (124494, 12)\n",
      "\n",
      "First few rows of the dataset:\n",
      "       date    device  failure    metric1  metric2  metric3  metric4  metric5  \\\n",
      "0  1/1/2015  S1F01085        0  215630672       55        0       52        6   \n",
      "1  1/1/2015  S1F0166B        0   61370680        0        3        0        6   \n",
      "2  1/1/2015  S1F01E6Y        0  173295968        0        0        0       12   \n",
      "3  1/1/2015  S1F01JE0        0   79694024        0        0        0        6   \n",
      "4  1/1/2015  S1F01R2B        0  135970480        0        0        0       15   \n",
      "\n",
      "   metric6  metric7  metric8  metric9  \n",
      "0   407438        0        0        7  \n",
      "1   403174        0        0        0  \n",
      "2   237394        0        0        0  \n",
      "3   410186        0        0        0  \n",
      "4   313173        0        0        3  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the SageMaker role and session\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "# Set up the S3 bucket and prefix\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"predictive-maintenance-feature-store\"\n",
    "\n",
    "# Load the data from S3\n",
    "s3_client = boto3.client('s3')\n",
    "s3_key = 'root/AAI-540_Predictive-Maintenance-for-Pharmaceutical-Manufacturing-Equipment/predictive_maintenance_dataset.csv'\n",
    "\n",
    "response = s3_client.get_object(Bucket=bucket, Key=s3_key)\n",
    "df = pd.read_csv(response['Body'])\n",
    "\n",
    "# Print dataset info\n",
    "print(\"Dataset loaded successfully. Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available buckets:\n",
      "  aws-athena-query-results-807494057176-us-east-1\n",
      "  sagemaker-us-east-1-807494057176\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# List all S3 buckets\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# Print the bucket names\n",
    "print(\"Available buckets:\")\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "142777ae-c072-448e-b941-72bc75735d01"
    }
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "f8976dad-6897-4c7e-8c95-ae2f53070ef5"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date    device  failure    metric1  metric2  metric3  metric4  \\\n",
      "57103    3/19/2015  W1F0Z3G1        0   77249240        0        0        0   \n",
      "80935    5/12/2015  Z1F0R8QZ        0  239701824        0       15        0   \n",
      "108623   7/31/2015  W1F1DPSA        0  238820120        0        0        0   \n",
      "19078    1/23/2015  W1F0Z4SP        0    2344904        0        0        0   \n",
      "76394     5/1/2015  S1F0FW8K        0  131957144        0        0        0   \n",
      "38590    2/20/2015  S1F0S387        0  204621608        0        2        0   \n",
      "123000  10/11/2015  S1F135GA        0  213125872        0        0        0   \n",
      "24900    1/31/2015  Z1F0E1CS        0  136402416        0        0        0   \n",
      "\n",
      "        metric5  metric6  metric7  metric8  metric9  \n",
      "57103        15   252142        0        0        0  \n",
      "80935        95   247988        0        0      155  \n",
      "108623       13       46        0        0        0  \n",
      "19078         8   192925        0        0        3  \n",
      "76394        92   246235        0        0        0  \n",
      "38590        12   270771        0        0       34  \n",
      "123000        8   253301        0        0        0  \n",
      "24900        10   311684        0        0       13  \n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# Define the file details\n",
    "filename = \"predictive_maintenance_dataset.csv\"\n",
    "bucket = \"sagemaker-us-east-1-807494057176\"  # The bucket you identified\n",
    "key = \"root/AAI-540_Predictive-Maintenance-for-Pharmaceutical-Manufacturing-Equipment/predictive_maintenance_dataset.csv\"\n",
    "\n",
    "# Download the file from S3\n",
    "s3.download_file(bucket, key, filename)\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "# Specify the columns for the dataset\n",
    "data.columns = [\n",
    "    \"date\",\n",
    "    \"device\",\n",
    "    \"failure\",\n",
    "    \"metric1\",\n",
    "    \"metric2\",\n",
    "    \"metric3\",\n",
    "    \"metric4\",\n",
    "    \"metric5\",\n",
    "    \"metric6\",\n",
    "    \"metric7\",\n",
    "    \"metric8\",\n",
    "    \"metric9\"\n",
    "]\n",
    "\n",
    "# Save the data to a new CSV file\n",
    "data.to_csv(\"data.csv\", sep=\",\", index=False)\n",
    "\n",
    "# Display a random sample of 8 rows from the dataset\n",
    "print(data.sample(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124494 entries, 0 to 124493\n",
      "Data columns (total 12 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   date     124494 non-null  object\n",
      " 1   device   124494 non-null  object\n",
      " 2   failure  124494 non-null  int64 \n",
      " 3   metric1  124494 non-null  int64 \n",
      " 4   metric2  124494 non-null  int64 \n",
      " 5   metric3  124494 non-null  int64 \n",
      " 6   metric4  124494 non-null  int64 \n",
      " 7   metric5  124494 non-null  int64 \n",
      " 8   metric6  124494 non-null  int64 \n",
      " 9   metric7  124494 non-null  int64 \n",
      " 10  metric8  124494 non-null  int64 \n",
      " 11  metric9  124494 non-null  int64 \n",
      "dtypes: int64(10), object(2)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key observations:\n",
    "\n",
    "* The dataset has 124,494 observations and 12 columns.\n",
    "* The first column is the date attribute, which might not be useful for training a machine learning model but could be useful for time-based analysis. We may choose to drop it for training but retain it for later analysis or output.\n",
    "* The second column is device, which represents the device ID. We will drop this before training but can add it back to the final output alongside failure probability predictions.\n",
    "* The third column is failure, which is the target variable. This indicates whether a device has failed (0 = No Failure; 1 = Failure). This will be the label we use for training the model.\n",
    "* There are 9 numeric features (metric1 through metric9) that represent various operational metrics from the devices. These features will be used for training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Validate and Production data\n",
    "Let's split the data as follows: 40% for training, 10% for validation, 10% for testing, and set 40% aside for our production dataset. We'll drop the 'device' field from the training, validation, and testing sets, as it is not a useful feature for training purposes. For our production set, however, we keep the 'device' feature. We may want to filter it out prior to running our inferences so that the input data features match those of the training set, and later use it to join with the inference results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (76377, 11)\n",
      "Validation set shape: (21799, 11)\n",
      "Testing set shape: (18877, 11)\n",
      "Production set shape: (7441, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert 'date' to datetime format if not already done\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n",
    "\n",
    "# Sort the dataset by date to maintain chronological order\n",
    "df = df.sort_values(by='date')\n",
    "\n",
    "# Define the cut-off points for each split\n",
    "train_cutoff = '2015-04-30'  # Training up to April\n",
    "val_cutoff = '2015-06-30'    # Validation in May and June\n",
    "test_cutoff = '2015-08-31'   # Testing in July and August\n",
    "prod_cutoff = '2015-11-02'   # Production in September to November\n",
    "\n",
    "# Create the time-based splits\n",
    "data_train = df[df['date'] <= train_cutoff].drop(['device'], axis=1)  # Training set (drop 'device')\n",
    "data_val = df[(df['date'] > train_cutoff) & (df['date'] <= val_cutoff)].drop(['device'], axis=1)  # Validation set\n",
    "data_test = df[(df['date'] > val_cutoff) & (df['date'] <= test_cutoff)].drop(['device'], axis=1)  # Testing set\n",
    "data_prod = df[(df['date'] > test_cutoff) & (df['date'] <= prod_cutoff)]  # Production set (keep 'device')\n",
    "\n",
    "# Output the shapes of the splits to verify\n",
    "print(\"Training set shape:\", data_train.shape)\n",
    "print(\"Validation set shape:\", data_val.shape)\n",
    "print(\"Testing set shape:\", data_test.shape)\n",
    "print(\"Production set shape:\", data_prod.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ff9d10f9-b611-423b-80da-6dcdafd1c8b9"
    }
   },
   "source": [
    "Let's upload those data sets in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "cd8e3431-79d9-40b6-91d1-d67cd61894e7"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets uploaded successfully to S3 bucket 'sagemaker-us-east-1-807494057176' with prefix 'predictive-maintenance-feature-store'.\n"
     ]
    }
   ],
   "source": [
    "# Save each dataset to CSV files and upload them to S3\n",
    "# 1. Training dataset\n",
    "train_file = \"train_data.csv\"\n",
    "data_train.to_csv(train_file, index=False, header=False)\n",
    "sess.upload_data(train_file, key_prefix=\"{}/train\".format(prefix))\n",
    "\n",
    "# 2. Validation dataset\n",
    "validation_file = \"validation_data.csv\"\n",
    "data_val.to_csv(validation_file, index=False, header=False)\n",
    "sess.upload_data(validation_file, key_prefix=\"{}/validation\".format(prefix))\n",
    "\n",
    "# 3. Testing dataset\n",
    "test_file = \"test_data.csv\"\n",
    "data_test.to_csv(test_file, index=False, header=False)\n",
    "sess.upload_data(test_file, key_prefix=\"{}/test\".format(prefix))\n",
    "\n",
    "# 4. Production dataset (keeping the 'device' column)\n",
    "production_file = \"production_data.csv\"\n",
    "data_prod.to_csv(production_file, index=False, header=False)\n",
    "sess.upload_data(production_file, key_prefix=\"{}/production\".format(prefix))\n",
    "\n",
    "# Output confirmation\n",
    "print(\"Datasets uploaded successfully to S3 bucket '{}' with prefix '{}'.\".format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets uploaded successfully to S3 bucket 'sagemaker-us-east-1-807494057176' with prefix 'predictive-maintenance-feature-store'.\n"
     ]
    }
   ],
   "source": [
    "# 5. Batch Inference dataset (dropping 'date', 'device', and 'failure')\n",
    "batch_file_noID = \"batch_data_noID.csv\"\n",
    "data_batch_noID = data_prod.drop(columns=['date', 'device', 'failure'])\n",
    "data_batch_noID.to_csv(batch_file_noID, index=False, header=False)\n",
    "sess.upload_data(batch_file_noID, key_prefix=\"{}/batch\".format(prefix))\n",
    "\n",
    "# Output confirmation\n",
    "print(f\"Datasets uploaded successfully to S3 bucket '{bucket}' with prefix '{prefix}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "71cbcebd-a2a5-419e-8e50-b2bc0909f564"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Training job and model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bd113b8e-adc1-4091-a26f-a426149fe604"
    }
   },
   "source": [
    "The below cell uses the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to kick off the training job using both our training set and validation set. Not that the objective is set to 'binary:logistic' which trains a model to output a probability between 0 and 1 (here the probability of a tumor being malignant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save CSV without headers\n",
    "data_train.to_csv(\"train_data.csv\", index=False, header=False)\n",
    "data_val.to_csv(\"validation_data.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'failure', 'metric1', 'metric2', 'metric3', 'metric4',\n",
      "       'metric5', 'metric6', 'metric7', 'metric8', 'metric9'],\n",
      "      dtype='object')\n",
      "Index(['date', 'failure', 'metric1', 'metric2', 'metric3', 'metric4',\n",
      "       'metric5', 'metric6', 'metric7', 'metric8', 'metric9'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_train.columns)\n",
    "print(data_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the 'date' column from training and validation datasets\n",
    "data_train = data_train.drop(columns=['date'])\n",
    "data_val = data_val.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['failure', 'metric1', 'metric2', 'metric3', 'metric4', 'metric5',\n",
      "       'metric6', 'metric7', 'metric8', 'metric9'],\n",
      "      dtype='object')\n",
      "Index(['failure', 'metric1', 'metric2', 'metric3', 'metric4', 'metric5',\n",
      "       'metric6', 'metric7', 'metric8', 'metric9'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_train.columns)\n",
    "print(data_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the cleaned datasets\n",
    "data_train.to_csv(\"train_data.csv\", index=False, header=False)\n",
    "data_val.to_csv(\"validation_data.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/validation/validation_data.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload to S3\n",
    "sess.upload_data(\"train_data.csv\", key_prefix=\"{}/train\".format(prefix))\n",
    "sess.upload_data(\"validation_data.csv\", key_prefix=\"{}/validation\".format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: xgb-2024-10-19-23-41-22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-19 23:41:24 Starting - Starting the training job...\n",
      "2024-10-19 23:41:39 Starting - Preparing the instances for training...\n",
      "2024-10-19 23:42:26 Downloading - Downloading the training image......\n",
      "2024-10-19 23:43:22 Training - Training image download completed. Training in progress..\u001b[34m[2024-10-19 23:43:27.224 ip-10-2-112-115.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:43:27.246 ip-10-2-112-115.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] File path /opt/ml/input/data/train of input files\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Making smlinks from folder /opt/ml/input/data/train to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] creating symlink between Path /opt/ml/input/data/train/train_data.csv and destination /tmp/sagemaker_xgboost_input_data/train_data.csv-3850515039890046937\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] File path /opt/ml/input/data/validation of input files\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Making smlinks from folder /opt/ml/input/data/validation to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] creating symlink between Path /opt/ml/input/data/validation/validation_data.csv and destination /tmp/sagemaker_xgboost_input_data/validation_data.csv607906596355070991\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Train matrix has 76377 rows and 9 columns\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Validation matrix has 21799 rows\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:43:27.702 ip-10-2-112-115.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:43:27.703 ip-10-2-112-115.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:43:27.704 ip-10-2-112-115.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:43:27.704 ip-10-2-112-115.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:43:27:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.51356#011validation-logloss:0.51374\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:43:27.779 ip-10-2-112-115.ec2.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:43:27.781 ip-10-2-112-115.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.39292#011validation-logloss:0.39325\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.30648#011validation-logloss:0.30698\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.24215#011validation-logloss:0.24279\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.19307#011validation-logloss:0.19386\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.15505#011validation-logloss:0.15596\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.12523#011validation-logloss:0.12627\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.10163#011validation-logloss:0.10282\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.08280#011validation-logloss:0.08412\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.06774#011validation-logloss:0.06919\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.05560#011validation-logloss:0.05720\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.04583#011validation-logloss:0.04755\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.03793#011validation-logloss:0.03978\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.03153#011validation-logloss:0.03351\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.02633#011validation-logloss:0.02844\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.02212#011validation-logloss:0.02434\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.01869#011validation-logloss:0.02103\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.01588#011validation-logloss:0.01835\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.01362#011validation-logloss:0.01619\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.01178#011validation-logloss:0.01443\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.01028#011validation-logloss:0.01306\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.00907#011validation-logloss:0.01196\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.00809#011validation-logloss:0.01114\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.00728#011validation-logloss:0.01040\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.00661#011validation-logloss:0.00986\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.00608#011validation-logloss:0.00944\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.00565#011validation-logloss:0.00912\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.00529#011validation-logloss:0.00890\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.00499#011validation-logloss:0.00872\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.00475#011validation-logloss:0.00857\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.00456#011validation-logloss:0.00847\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.00441#011validation-logloss:0.00844\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.00430#011validation-logloss:0.00840\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.00419#011validation-logloss:0.00841\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.00410#011validation-logloss:0.00837\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.00404#011validation-logloss:0.00833\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.00397#011validation-logloss:0.00842\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.00394#011validation-logloss:0.00848\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.00389#011validation-logloss:0.00850\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.00386#011validation-logloss:0.00857\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.00384#011validation-logloss:0.00860\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.00381#011validation-logloss:0.00865\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.00381#011validation-logloss:0.00866\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.00379#011validation-logloss:0.00867\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.00378#011validation-logloss:0.00864\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.00378#011validation-logloss:0.00864\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.00376#011validation-logloss:0.00872\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.00375#011validation-logloss:0.00872\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.00375#011validation-logloss:0.00872\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.00373#011validation-logloss:0.00872\u001b[0m\n",
      "\u001b[34m[50]#011train-logloss:0.00373#011validation-logloss:0.00874\u001b[0m\n",
      "\u001b[34m[51]#011train-logloss:0.00373#011validation-logloss:0.00874\u001b[0m\n",
      "\u001b[34m[52]#011train-logloss:0.00370#011validation-logloss:0.00870\u001b[0m\n",
      "\u001b[34m[53]#011train-logloss:0.00369#011validation-logloss:0.00873\u001b[0m\n",
      "\u001b[34m[54]#011train-logloss:0.00369#011validation-logloss:0.00874\u001b[0m\n",
      "\u001b[34m[55]#011train-logloss:0.00368#011validation-logloss:0.00874\u001b[0m\n",
      "\u001b[34m[56]#011train-logloss:0.00368#011validation-logloss:0.00875\u001b[0m\n",
      "\u001b[34m[57]#011train-logloss:0.00366#011validation-logloss:0.00868\u001b[0m\n",
      "\u001b[34m[58]#011train-logloss:0.00366#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[59]#011train-logloss:0.00366#011validation-logloss:0.00868\u001b[0m\n",
      "\u001b[34m[60]#011train-logloss:0.00366#011validation-logloss:0.00868\u001b[0m\n",
      "\u001b[34m[61]#011train-logloss:0.00366#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[62]#011train-logloss:0.00366#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[63]#011train-logloss:0.00366#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[64]#011train-logloss:0.00366#011validation-logloss:0.00870\u001b[0m\n",
      "\u001b[34m[65]#011train-logloss:0.00366#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[66]#011train-logloss:0.00364#011validation-logloss:0.00872\u001b[0m\n",
      "\u001b[34m[67]#011train-logloss:0.00364#011validation-logloss:0.00871\u001b[0m\n",
      "\u001b[34m[68]#011train-logloss:0.00364#011validation-logloss:0.00871\u001b[0m\n",
      "\u001b[34m[69]#011train-logloss:0.00362#011validation-logloss:0.00867\u001b[0m\n",
      "\u001b[34m[70]#011train-logloss:0.00362#011validation-logloss:0.00865\u001b[0m\n",
      "\u001b[34m[71]#011train-logloss:0.00362#011validation-logloss:0.00867\u001b[0m\n",
      "\u001b[34m[72]#011train-logloss:0.00362#011validation-logloss:0.00867\u001b[0m\n",
      "\u001b[34m[73]#011train-logloss:0.00362#011validation-logloss:0.00868\u001b[0m\n",
      "\u001b[34m[74]#011train-logloss:0.00362#011validation-logloss:0.00868\u001b[0m\n",
      "\u001b[34m[75]#011train-logloss:0.00362#011validation-logloss:0.00868\u001b[0m\n",
      "\u001b[34m[76]#011train-logloss:0.00362#011validation-logloss:0.00867\u001b[0m\n",
      "\u001b[34m[77]#011train-logloss:0.00362#011validation-logloss:0.00868\u001b[0m\n",
      "\u001b[34m[78]#011train-logloss:0.00362#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[79]#011train-logloss:0.00362#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[80]#011train-logloss:0.00362#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[81]#011train-logloss:0.00362#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[82]#011train-logloss:0.00362#011validation-logloss:0.00867\u001b[0m\n",
      "\u001b[34m[83]#011train-logloss:0.00360#011validation-logloss:0.00865\u001b[0m\n",
      "\u001b[34m[84]#011train-logloss:0.00360#011validation-logloss:0.00865\u001b[0m\n",
      "\u001b[34m[85]#011train-logloss:0.00359#011validation-logloss:0.00866\u001b[0m\n",
      "\u001b[34m[86]#011train-logloss:0.00359#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[87]#011train-logloss:0.00359#011validation-logloss:0.00870\u001b[0m\n",
      "\u001b[34m[88]#011train-logloss:0.00359#011validation-logloss:0.00870\u001b[0m\n",
      "\u001b[34m[89]#011train-logloss:0.00359#011validation-logloss:0.00868\u001b[0m\n",
      "\u001b[34m[90]#011train-logloss:0.00359#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[91]#011train-logloss:0.00359#011validation-logloss:0.00870\u001b[0m\n",
      "\u001b[34m[92]#011train-logloss:0.00359#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[93]#011train-logloss:0.00359#011validation-logloss:0.00867\u001b[0m\n",
      "\u001b[34m[94]#011train-logloss:0.00359#011validation-logloss:0.00868\u001b[0m\n",
      "\u001b[34m[95]#011train-logloss:0.00359#011validation-logloss:0.00871\u001b[0m\n",
      "\u001b[34m[96]#011train-logloss:0.00358#011validation-logloss:0.00869\u001b[0m\n",
      "\u001b[34m[97]#011train-logloss:0.00358#011validation-logloss:0.00867\u001b[0m\n",
      "\u001b[34m[98]#011train-logloss:0.00357#011validation-logloss:0.00871\u001b[0m\n",
      "\u001b[34m[99]#011train-logloss:0.00357#011validation-logloss:0.00871\u001b[0m\n",
      "\n",
      "2024-10-19 23:43:46 Uploading - Uploading generated training model\n",
      "2024-10-19 23:43:46 Completed - Training job completed\n",
      "Training seconds: 99\n",
      "Billable seconds: 99\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "import sagemaker\n",
    "\n",
    "# Generate a unique job name\n",
    "job_name = \"xgb-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "output_location = \"s3://{}/{}/output/{}\".format(bucket, prefix, job_name)\n",
    "\n",
    "# Retrieve the XGBoost container image for the current region\n",
    "image = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\", region=boto3.Session().region_name, version=\"1.7-1\"\n",
    ")\n",
    "\n",
    "# Create the XGBoost estimator\n",
    "sm_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size=50,\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "# Set the hyperparameters for the XGBoost model\n",
    "sm_estimator.set_hyperparameters(\n",
    "    objective=\"binary:logistic\",  # Binary classification\n",
    "    max_depth=5,                  # Maximum depth of trees\n",
    "    eta=0.2,                      # Learning rate\n",
    "    gamma=4,                      # Minimum loss reduction required for a split\n",
    "    min_child_weight=6,           # Minimum sum of instance weight in a child\n",
    "    subsample=0.8,                # Subsample ratio\n",
    "    verbosity=0,                  # Silent training output\n",
    "    num_round=100,                # Number of boosting rounds\n",
    ")\n",
    "\n",
    "# Define the input data channels for training and validation\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train\".format(bucket, prefix),\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validation\".format(bucket, prefix),\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}\n",
    "\n",
    "# Start the training job and monitor logs\n",
    "sm_estimator.fit(inputs=data_channels, job_name=job_name, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/output/xgb-2024-10-19-23-41-22\n"
     ]
    }
   ],
   "source": [
    "# Check output location\n",
    "output_location = \"s3://{}/{}/output/{}\".format(bucket, prefix, job_name)\n",
    "print(output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "397fb60a-c48b-453f-88ea-4d832b70c919"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Batch Transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a transform job with the default configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-10-19-23-44-09-820\n",
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2024-10-19-23-44-10-505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................\n",
      "\u001b[34m[2024-10-19:23:51:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:04:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:04:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"POST /invocations HTTP/1.1\" 200 167315 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"POST /invocations HTTP/1.1\" 200 167315 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-19T23:51:10.464:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:04:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2024-10-19 23:51:04 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:04:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2024-10-19 23:51:04 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:06:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-19:23:51:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"POST /invocations HTTP/1.1\" 200 167315 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-19:23:51:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Oct/2024:23:51:10 +0000] \"POST /invocations HTTP/1.1\" 200 167315 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-19T23:51:10.464:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "import sagemaker\n",
    "\n",
    "# Set up the transformer with the trained model\n",
    "sm_transformer = sm_estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",  # Set instance type for batch processing\n",
    "    output_path=\"s3://{}/{}/batch-inference-output\".format(bucket, prefix)  # Output path\n",
    ")\n",
    "\n",
    "# Input location (batch data without 'date' and 'device' columns)\n",
    "input_location = \"s3://{}/{}/batch/batch_data_noID.csv\".format(bucket, prefix)\n",
    "\n",
    "# Start the Batch Transform job\n",
    "sm_transformer.transform(\n",
    "    data=input_location,\n",
    "    content_type=\"text/csv\",\n",
    "    split_type=\"Line\"  # Process each line of the CSV as an individual input\n",
    ")\n",
    "\n",
    "# Wait for the transform job to complete\n",
    "sm_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output of the Batch Transform job in S3. It should show the list probabilities of failures of a device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, batch_file):\n",
    "    file_name = \"{}.out\".format(batch_file)\n",
    "    match = re.match(\"s3://([^/]+)/(.*)\", \"{}/{}\".format(s3uri, file_name))\n",
    "    output_bucket, output_prefix = match.group(1), match.group(2)\n",
    "    s3.download_file(output_bucket, output_prefix, file_name)\n",
    "    return pd.read_csv(file_name, sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.002610\n",
       "1  0.000298\n",
       "2  0.000066\n",
       "3  0.000669\n",
       "4  0.000269\n",
       "5  0.000107\n",
       "6  0.000446\n",
       "7  0.000225"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = get_csv_output_from_s3(sm_transformer.output_path, batch_file_noID)\n",
    "output_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Join the input and the prediction results \n",
    "Now, let's associate the prediction results with their corresponding input records. We can also use the __input_filter__ to exclude the ID column easily and there's no need to have a separate file in S3.\n",
    "\n",
    "* Set __input_filter__ to \"$[1:]\": indicates that we are excluding column 0 (the 'ID') before processing the inferences and keeping everything from column 1 to the last column (all the features or predictors)  \n",
    "  \n",
    "  \n",
    "* Set __join_source__ to \"Input\": indicates our desire to join the input data with the inference results  \n",
    "\n",
    "* Leave __output_filter__ to default ('$'), indicating that the joined input and inference results be will saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2024-10-19-23-55-49-400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................\n",
      "\u001b[34m[2024-10-20:00:02:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:19:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:19:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [20] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [20] [INFO] Listening at: unix:/tmp/gunicorn.sock (20)\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [20] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [20] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [20] [INFO] Listening at: unix:/tmp/gunicorn.sock (20)\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [20] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:25:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"POST /invocations HTTP/1.1\" 200 167315 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:25:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"POST /invocations HTTP/1.1\" 200 167315 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-20T00:02:25.424:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:19:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:19:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [20] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [20] [INFO] Listening at: unix:/tmp/gunicorn.sock (20)\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [20] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:02:20 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [20] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [20] [INFO] Listening at: unix:/tmp/gunicorn.sock (20)\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [20] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:02:20 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:22:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:02:25:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"POST /invocations HTTP/1.1\" 200 167315 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:25:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:02:25:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [20/Oct/2024:00:02:25 +0000] \"POST /invocations HTTP/1.1\" 200 167315 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-20T00:02:25.424:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Required configurations for the batch transform\n",
    "sm_transformer.assemble_with = \"Line\"\n",
    "sm_transformer.accept = \"text/csv\"\n",
    "\n",
    "# Input location (batch data without 'date', 'device', and 'failure' columns)\n",
    "input_location = \"s3://{}/{}/batch/{}\".format(bucket, prefix, batch_file_noID)\n",
    "\n",
    "# Start a transform job\n",
    "sm_transformer.transform(\n",
    "    input_location,\n",
    "    split_type=\"Line\",\n",
    "    content_type=\"text/csv\",\n",
    "    join_source=\"Input\",  # Join the input data with the prediction results\n",
    ")\n",
    "\n",
    "# Wait for the transform job to complete\n",
    "sm_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output of the Batch Transform job in S3. It should show the list of failures and probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139851104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>376564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207060288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>372208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145452104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12870608</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>323213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154655112</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>262558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146152808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>221471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68643440</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>353212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1450432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>287598</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1   2    3   4       5  6  7    8         9\n",
       "0  139851104  0   0  112  20  376564  0  0    0  0.002610\n",
       "1  207060288  0   0    0  19  372208  0  0    0  0.000298\n",
       "2  145452104  0   0    0   7      31  0  0    0  0.000066\n",
       "3   12870608  0  34    0  23  323213  0  0  205  0.000669\n",
       "4  154655112  0   7    0   8  262558  0  0    0  0.000269\n",
       "5  146152808  0   0    0   9  221471  0  0    0  0.000107\n",
       "6   68643440  0   0    0  19  353212  0  0    1  0.000446\n",
       "7    1450432  0   0    0   9  287598  0  0    0  0.000225"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure we use the correct file name (batch_data_noID.csv) for the output\n",
    "batch_file_noID = \"batch_data_noID.csv\"\n",
    "\n",
    "# Retrieve and display the output from S3 using the correct batch file\n",
    "output_df = get_csv_output_from_s3(sm_transformer.output_path, batch_file_noID)\n",
    "output_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     device          0  1   2    3   4       5  6  7    8         9\n",
      "0  W1F1CL1K  139851104  0   0  112  20  376564  0  0    0  0.002610\n",
      "1  W1F1BTB2  207060288  0   0    0  19  372208  0  0    0  0.000298\n",
      "2  W1F1C9HM  145452104  0   0    0   7      31  0  0    0  0.000066\n",
      "3  W1F1CHY9   12870608  0  34    0  23  323213  0  0  205  0.000669\n",
      "4  W1F1CJ3G  154655112  0   7    0   8  262558  0  0    0  0.000269\n"
     ]
    }
   ],
   "source": [
    "# Re-add the 'device' column to the output dataframe\n",
    "output_with_device = pd.concat([data_prod['device'].reset_index(drop=True), output_df], axis=1)\n",
    "\n",
    "# View the final dataframe with predictions and device column\n",
    "print(output_with_device.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Update the output filter to keep only ID and prediction results\n",
    "Let's change __output_filter__ to \"$[0,-1]\", indicating that when presenting the output, we only want to keep column 0 (the 'ID') and the last column (the inference result i.e. the probability of a given tumor to be malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2024-10-20-00-02-54-250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................\n",
      "\u001b[34m[2024-10-20:00:10:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:24:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:10:31 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:10:31 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:31:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:10:32 +0000] \"POST /invocations HTTP/1.1\" 200 162266 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-20T00:10:31.668:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:24:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:24:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2024-10-20 00:10:25 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:10:25 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:10:25 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:10:25 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:10:25 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:10:25 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:10:25 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2024-10-20 00:10:25 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:27:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:10:31 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:10:31 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-20:00:10:31:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [20/Oct/2024:00:10:31 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [20/Oct/2024:00:10:31 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-20:00:10:31:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [20/Oct/2024:00:10:32 +0000] \"POST /invocations HTTP/1.1\" 200 162266 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [20/Oct/2024:00:10:32 +0000] \"POST /invocations HTTP/1.1\" 200 162266 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-20T00:10:31.668:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# start another transform job\n",
    "sm_transformer.transform(\n",
    "    input_location,\n",
    "    split_type=\"Line\",\n",
    "    content_type=\"text/csv\",\n",
    "    input_filter=\"$[1:]\",\n",
    "    join_source=\"Input\",\n",
    "    output_filter=\"$[0,-1]\",\n",
    ")\n",
    "sm_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's inspect the output of the Batch Transform job in S3 again. It should show 2 columns: the device and their corresponding probabilities of failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139851104</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207060288</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145452104</td>\n",
       "      <td>0.003224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12870608</td>\n",
       "      <td>0.007542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154655112</td>\n",
       "      <td>0.005833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146152808</td>\n",
       "      <td>0.003520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68643440</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1450432</td>\n",
       "      <td>0.003520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0  139851104  0.003703\n",
       "1  207060288  0.003703\n",
       "2  145452104  0.003224\n",
       "3   12870608  0.007542\n",
       "4  154655112  0.005833\n",
       "5  146152808  0.003520\n",
       "6   68643440  0.003703\n",
       "7    1450432  0.003520"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = get_csv_output_from_s3(sm_transformer.output_path, batch_file_noID)\n",
    "output_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_model(role=role, image_uri=XGBOOST_IMAGE)In summary, we can use newly introduced 3 attributes - __input_filter__, __join_source__, __output_filter__ to \n",
    "1. Filter / select useful features from the input dataset. e.g. exclude ID columns.\n",
    "2. Associate the prediction results with their corresponding input records.\n",
    "3. Filter the original or joined results before saving to S3. e.g. keep ID and probability columns only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the Sagemaker Model created during our training job to the Sagemaker Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TrainingJobSummaries': [{'TrainingJobName': 'xgb-2024-10-19-23-41-22', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/xgb-2024-10-19-23-41-22', 'CreationTime': datetime.datetime(2024, 10, 19, 23, 41, 22, 815000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 10, 19, 23, 43, 45, 742000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 10, 19, 23, 43, 46, 259000, tzinfo=tzlocal()), 'TrainingJobStatus': 'Completed'}, {'TrainingJobName': 'xgb-2024-10-16-21-59-14', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/xgb-2024-10-16-21-59-14', 'CreationTime': datetime.datetime(2024, 10, 16, 21, 59, 14, 306000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 10, 16, 22, 1, 35, 715000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 10, 16, 22, 1, 36, 113000, tzinfo=tzlocal()), 'TrainingJobStatus': 'Completed'}, {'TrainingJobName': 'xgb-2024-10-16-17-53-36', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/xgb-2024-10-16-17-53-36', 'CreationTime': datetime.datetime(2024, 10, 16, 17, 53, 36, 405000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 10, 16, 17, 56, 3, 373000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 10, 16, 17, 56, 3, 967000, tzinfo=tzlocal()), 'TrainingJobStatus': 'Completed'}, {'TrainingJobName': 'xgb-2024-10-16-17-44-08', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/xgb-2024-10-16-17-44-08', 'CreationTime': datetime.datetime(2024, 10, 16, 17, 44, 8, 948000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 10, 16, 17, 46, 41, 354000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 10, 16, 17, 46, 41, 905000, tzinfo=tzlocal()), 'TrainingJobStatus': 'Failed'}, {'TrainingJobName': 'pipelines-g4stdgqk7kpc-AbaloneTrain-ih7qtzDnCv', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/pipelines-g4stdgqk7kpc-AbaloneTrain-ih7qtzDnCv', 'CreationTime': datetime.datetime(2024, 10, 13, 13, 8, 21, 715000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 10, 13, 13, 10, 32, 858000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 10, 13, 13, 10, 33, 83000, tzinfo=tzlocal()), 'TrainingJobStatus': 'Completed'}, {'TrainingJobName': 'pipelines-1uc9p2dihqs1-AbaloneTrain-yghNxj7pIB', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/pipelines-1uc9p2dihqs1-AbaloneTrain-yghNxj7pIB', 'CreationTime': datetime.datetime(2024, 10, 13, 12, 55, 18, 728000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 10, 13, 12, 57, 27, 159000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 10, 13, 12, 57, 27, 456000, tzinfo=tzlocal()), 'TrainingJobStatus': 'Completed'}, {'TrainingJobName': 'pipelines-7i325hh76518-AbaloneTrain-CTY96g9Jxf', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/pipelines-7i325hh76518-AbaloneTrain-CTY96g9Jxf', 'CreationTime': datetime.datetime(2024, 10, 13, 12, 39, 7, 755000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 10, 13, 12, 41, 16, 814000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 10, 13, 12, 41, 17, 451000, tzinfo=tzlocal()), 'TrainingJobStatus': 'Completed'}, {'TrainingJobName': 'xgb-2024-09-29-15-08-53', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/xgb-2024-09-29-15-08-53', 'CreationTime': datetime.datetime(2024, 9, 29, 15, 8, 53, 425000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 9, 29, 15, 11, 28, 870000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 9, 29, 15, 11, 29, 386000, tzinfo=tzlocal()), 'TrainingJobStatus': 'Completed'}, {'TrainingJobName': 'sagemaker-scikit-learn-2024-09-24-02-42-39-107', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/sagemaker-scikit-learn-2024-09-24-02-42-39-107', 'CreationTime': datetime.datetime(2024, 9, 24, 2, 42, 39, 360000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 9, 24, 2, 44, 39, 963000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 9, 24, 2, 44, 40, 509000, tzinfo=tzlocal()), 'TrainingJobStatus': 'Failed'}, {'TrainingJobName': 'sagemaker-scikit-learn-2024-09-24-02-31-32-868', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/sagemaker-scikit-learn-2024-09-24-02-31-32-868', 'CreationTime': datetime.datetime(2024, 9, 24, 2, 31, 33, 99000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 9, 24, 2, 33, 38, 926000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 9, 24, 2, 33, 39, 209000, tzinfo=tzlocal()), 'TrainingJobStatus': 'Failed'}], 'NextToken': 'cIws2QhTXUIa8bi8Va1Z1ghfkar5qnmWwSFexDefOZhA1MOeQ2rl957dEfThjhC4RGuxLZ2B3P44JTvavswkgUcy8LN7AboYXM1bDpYX+v0ejQ8Jt6euhZ1+MWjDziDUUyszdkFSaQ61aJlPU7trkapRBGFSeSKglMVT9KNNjEsfLX5P4DE1fvTl8XvTsXWi0x3Zj5MjZCDdoqoPk7g4ECTGON1MyxfM8F5nrzE1axkTAeiAIGFD4MQEv7FMVohm+E0O7GxXmFkPjyiSfV/G5u5a0TUQWS9C1c+8DVDJ9iWCL664LjykIPU35tBe5qQt8QPIVfyPHaul3Mq96mgWQZUwQGgc5114fyUvCHWDJEmn45Nik6qy54IlxgjlXkBX7tt9nF8JzCEYyiYZm09+fupxG2OjexGtWku0YH9Ger8LD/vOUWYqz8h5w8iOzEUfRkh6Jf+wgDyCJMiNj03/h1wBDDG1T+QgUFeQr8X5Oq/4+1IyfIJN1ly1cLk7ZVwDyw9B0CIaZHg/a8G07yK2R8meOxYplUaWL3DQNVE1zNY+', 'ResponseMetadata': {'RequestId': '585c71ac-7299-4d9a-95a3-7866e5bf44ba', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '585c71ac-7299-4d9a-95a3-7866e5bf44ba', 'content-type': 'application/x-amz-json-1.1', 'content-length': '3887', 'date': 'Sun, 20 Oct 2024 00:11:58 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "# Create a SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# List training jobs\n",
    "training_jobs = sagemaker_session.sagemaker_client.list_training_jobs()\n",
    "\n",
    "# Display training jobs\n",
    "print(training_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: sagemaker-xgboost-2024-10-20-00-02-54-250\n",
      "Model Data S3 Path: s3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/output/xgb-2024-10-16-21-59-14/xgb-2024-10-16-21-59-14/output/model.tar.gz\n",
      "Model ARN: arn:aws:sagemaker:us-east-1:807494057176:model/sagemaker-xgboost-2024-10-20-00-02-54-250\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the SageMaker client\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "\n",
    "# Use the newest model name\n",
    "model_name = \"sagemaker-xgboost-2024-10-20-00-02-54-250\"\n",
    "print(f\"Model Name: {model_name}\")\n",
    "\n",
    "# Retrieve the training job details\n",
    "info = sagemaker.describe_training_job(TrainingJobName=\"xgb-2024-10-16-21-59-14\")  # Updated with the newest training job name\n",
    "\n",
    "# Get the model artifacts S3 path\n",
    "model_data = info[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(f\"Model Data S3 Path: {model_data}\")\n",
    "\n",
    "# Define the primary container\n",
    "primary_container = {\n",
    "    \"Image\": image,  # Make sure the 'image' variable is defined (this could be the XGBoost image URI)\n",
    "    \"ModelDataUrl\": model_data\n",
    "}\n",
    "\n",
    "# Save the model to the SageMaker Model Registry\n",
    "create_model_response = sagemaker.create_model(\n",
    "    ModelName=model_name, \n",
    "    ExecutionRoleArn=role,  # Ensure 'role' contains the appropriate SageMaker execution role ARN\n",
    "    PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "# Print the ARN of the created model\n",
    "print(f\"Model ARN: {create_model_response['ModelArn']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainingJobName': 'xgb-2024-10-16-21-59-14',\n",
       " 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:training-job/xgb-2024-10-16-21-59-14',\n",
       " 'ModelArtifacts': {'S3ModelArtifacts': 's3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/output/xgb-2024-10-16-21-59-14/xgb-2024-10-16-21-59-14/output/model.tar.gz'},\n",
       " 'TrainingJobStatus': 'Completed',\n",
       " 'SecondaryStatus': 'Completed',\n",
       " 'HyperParameters': {'eta': '0.2',\n",
       "  'gamma': '4',\n",
       "  'max_depth': '5',\n",
       "  'min_child_weight': '6',\n",
       "  'num_round': '100',\n",
       "  'objective': 'binary:logistic',\n",
       "  'subsample': '0.8',\n",
       "  'verbosity': '0'},\n",
       " 'AlgorithmSpecification': {'TrainingImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.7-1',\n",
       "  'TrainingInputMode': 'File',\n",
       "  'MetricDefinitions': [{'Name': 'train:mae',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-mae:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:aucpr',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-aucpr:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:f1_binary',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-f1_binary:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:mae',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-mae:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:logloss',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-logloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:f1',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-f1:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:accuracy',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-accuracy:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:mse',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-mse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:recall',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-recall:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:poisson-nloglik',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-poisson-nloglik:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:precision',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-precision:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:error',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-error:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:ndcg',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-ndcg:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:map',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-map:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:f1_binary',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-f1_binary:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:auc',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-auc:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:auc',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-auc:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:error',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-error:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:poisson-nloglik',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-poisson-nloglik:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:rmse',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-rmse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:logloss',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-logloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:accuracy',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-accuracy:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:aucpr',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-aucpr:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:balanced_accuracy',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-balanced_accuracy:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:rmse',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-rmse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:mse',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-mse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:ndcg',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-ndcg:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:f1',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-f1:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:map',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-map:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'}],\n",
       "  'EnableSageMakerMetricsTimeSeries': False},\n",
       " 'RoleArn': 'arn:aws:iam::807494057176:role/LabRole',\n",
       " 'InputDataConfig': [{'ChannelName': 'train',\n",
       "   'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "     'S3Uri': 's3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/train',\n",
       "     'S3DataDistributionType': 'FullyReplicated'}},\n",
       "   'ContentType': 'text/csv',\n",
       "   'CompressionType': 'None',\n",
       "   'RecordWrapperType': 'None'},\n",
       "  {'ChannelName': 'validation',\n",
       "   'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "     'S3Uri': 's3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/validation',\n",
       "     'S3DataDistributionType': 'FullyReplicated'}},\n",
       "   'ContentType': 'text/csv',\n",
       "   'CompressionType': 'None',\n",
       "   'RecordWrapperType': 'None'}],\n",
       " 'OutputDataConfig': {'KmsKeyId': '',\n",
       "  'S3OutputPath': 's3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/output/xgb-2024-10-16-21-59-14',\n",
       "  'CompressionType': 'GZIP'},\n",
       " 'ResourceConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "  'InstanceCount': 1,\n",
       "  'VolumeSizeInGB': 50},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'CreationTime': datetime.datetime(2024, 10, 16, 21, 59, 14, 306000, tzinfo=tzlocal()),\n",
       " 'TrainingStartTime': datetime.datetime(2024, 10, 16, 21, 59, 51, 5000, tzinfo=tzlocal()),\n",
       " 'TrainingEndTime': datetime.datetime(2024, 10, 16, 22, 1, 35, 715000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 10, 16, 22, 1, 36, 113000, tzinfo=tzlocal()),\n",
       " 'SecondaryStatusTransitions': [{'Status': 'Starting',\n",
       "   'StartTime': datetime.datetime(2024, 10, 16, 21, 59, 14, 306000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2024, 10, 16, 21, 59, 51, 5000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Preparing the instances for training'},\n",
       "  {'Status': 'Downloading',\n",
       "   'StartTime': datetime.datetime(2024, 10, 16, 21, 59, 51, 5000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2024, 10, 16, 22, 1, 7, 374000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Downloading the training image'},\n",
       "  {'Status': 'Training',\n",
       "   'StartTime': datetime.datetime(2024, 10, 16, 22, 1, 7, 374000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2024, 10, 16, 22, 1, 22, 839000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training image download completed. Training in progress.'},\n",
       "  {'Status': 'Uploading',\n",
       "   'StartTime': datetime.datetime(2024, 10, 16, 22, 1, 22, 839000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2024, 10, 16, 22, 1, 35, 715000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Uploading generated training model'},\n",
       "  {'Status': 'Completed',\n",
       "   'StartTime': datetime.datetime(2024, 10, 16, 22, 1, 35, 715000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2024, 10, 16, 22, 1, 35, 715000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training job completed'}],\n",
       " 'FinalMetricDataList': [{'MetricName': 'validation:logloss',\n",
       "   'Value': 0.008709999732673168,\n",
       "   'Timestamp': datetime.datetime(2024, 10, 16, 22, 1, 20, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:logloss',\n",
       "   'Value': 0.0035699999425560236,\n",
       "   'Timestamp': datetime.datetime(2024, 10, 16, 22, 1, 20, tzinfo=tzlocal())}],\n",
       " 'EnableNetworkIsolation': False,\n",
       " 'EnableInterContainerTrafficEncryption': False,\n",
       " 'EnableManagedSpotTraining': False,\n",
       " 'TrainingTimeInSeconds': 104,\n",
       " 'BillableTimeInSeconds': 104,\n",
       " 'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/output/xgb-2024-10-16-21-59-14',\n",
       "  'CollectionConfigurations': []},\n",
       " 'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/output/xgb-2024-10-16-21-59-14',\n",
       "  'ProfilingIntervalInMilliseconds': 500,\n",
       "  'DisableProfiler': False},\n",
       " 'ProfilingStatus': 'Enabled',\n",
       " 'ResponseMetadata': {'RequestId': '8b9158aa-9675-4704-8a1f-af9c34b44032',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '8b9158aa-9675-4704-8a1f-af9c34b44032',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '7323',\n",
       "   'date': 'Sun, 20 Oct 2024 00:12:09 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect Training Job Details\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created EndpointConfig: arn:aws:sagemaker:us-east-1:807494057176:endpoint-config/project-endpoint-config-2024-10-20-00-12-20\n"
     ]
    }
   ],
   "source": [
    "# Create Endpoint Configuration\n",
    "\n",
    "\n",
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "# Create an endpoint config name using the current timestamp\n",
    "endpoint_config_name = 'project-endpoint-config-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# Specify the instance type for hosting the model\n",
    "instance_type = 'ml.m5.xlarge'\n",
    "\n",
    "# Create the endpoint configuration\n",
    "endpoint_config_response = sagemaker.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,  # This name will be used in the CreateEndpoint request.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",        # Name for the production variant\n",
    "            \"ModelName\": model_name,          # Name of the model to deploy\n",
    "            \"InstanceType\": instance_type,    # Compute instance type\n",
    "            \"InitialInstanceCount\": 1         # Number of instances to launch initially\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the created endpoint configuration ARN\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy our model to real-time endpoint\n",
    "\n",
    "endpoint_name = 'project-endpoint' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())                            \n",
    "\n",
    "\n",
    "create_endpoint_response = sagemaker.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Endpoint Status...\n",
      "Endpoint project-endpoint2024-10-20-00-12-24 is still creating. Waiting for 60 seconds...\n",
      "Checking Endpoint Status...\n",
      "Endpoint project-endpoint2024-10-20-00-12-24 is still creating. Waiting for 60 seconds...\n",
      "Checking Endpoint Status...\n",
      "Endpoint project-endpoint2024-10-20-00-12-24 is still creating. Waiting for 60 seconds...\n",
      "Checking Endpoint Status...\n",
      "Endpoint project-endpoint2024-10-20-00-12-24 is still creating. Waiting for 60 seconds...\n",
      "Checking Endpoint Status...\n",
      "Endpoint project-endpoint2024-10-20-00-12-24 is now InService and ready to use.\n"
     ]
    }
   ],
   "source": [
    "import time  # Ensure time library is imported for sleep\n",
    "\n",
    "# Describe the endpoint status and wait until it's 'InService'\n",
    "def wait_for_endpoint(endpoint_name):\n",
    "    while True:\n",
    "        print(\"Checking Endpoint Status...\")\n",
    "        res = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "        state = res[\"EndpointStatus\"]\n",
    "\n",
    "        if state == \"InService\":\n",
    "            print(f\"Endpoint {endpoint_name} is now InService and ready to use.\")\n",
    "            break\n",
    "        elif state == \"Creating\":\n",
    "            print(f\"Endpoint {endpoint_name} is still creating. Waiting for 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "        else:\n",
    "            print(f\"Error: Endpoint {endpoint_name} creation failed with status '{state}'.\")\n",
    "            print(\"Please check the SageMaker Console for more details.\")\n",
    "            break\n",
    "\n",
    "# Call the function to monitor the endpoint status\n",
    "wait_for_endpoint(endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002609927672892809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Invoke Endpoint\n",
    "\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "                            EndpointName=endpoint_name,\n",
    "                            ContentType='text/csv',\n",
    "                            Body=data_batch_noID.to_csv(header=None, index=False).strip('\\n').split('\\n')[0]\n",
    "                            )\n",
    "print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'fdca1f8d-6835-45f3-bb21-2c84c2920b3f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'fdca1f8d-6835-45f3-bb21-2c84c2920b3f',\n",
       "   'x-amzn-invoked-production-variant': 'variant1',\n",
       "   'date': 'Sun, 20 Oct 2024 00:16:27 GMT',\n",
       "   'content-type': 'text/csv; charset=utf-8',\n",
       "   'content-length': '21',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ContentType': 'text/csv; charset=utf-8',\n",
       " 'InvokedProductionVariant': 'variant1',\n",
       " 'Body': <botocore.response.StreamingBody at 0x7f08fab7f730>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine Response Body\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   probability  label\n",
      "0     0.003703      0\n",
      "1     0.003703      0\n",
      "2     0.003224      0\n",
      "3     0.007542      0\n",
      "4     0.005833      0\n",
      "5     0.003520      0\n",
      "6     0.003703      0\n",
      "7     0.003520      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original validation data\n",
    "validation_data = pd.read_csv(\"validation_data.csv\")\n",
    "\n",
    "# Extract the probability column from the output DataFrame\n",
    "probabilities = output_df[[1]].reset_index(drop=True)\n",
    "probabilities.columns = ['probability']\n",
    "\n",
    "# Extract the label column from column 0 of the original validation data\n",
    "labels = validation_data.iloc[:, 0].reset_index(drop=True)\n",
    "labels.name = 'label'\n",
    "\n",
    "# Combine probabilities and labels into the final DataFrame with probability first\n",
    "validation_with_predictions = pd.concat([probabilities, labels], axis=1)\n",
    "\n",
    "# Save to CSV with 'probability' and 'label' columns\n",
    "validation_with_predictions.to_csv(\"validation_with_predictions.csv\", index=False)\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "print(validation_with_predictions.head(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'bee39720-7804-42a8-bbc6-c0c72a7c0a35',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'bee39720-7804-42a8-bbc6-c0c72a7c0a35',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sun, 20 Oct 2024 01:40:53 GMT',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete Endpoint\n",
    "\n",
    "sagemaker.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the License). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the license file accompanying this file. This file is distributed on an AS IS BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
