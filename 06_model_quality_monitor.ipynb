{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Quality Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Maintenance for Pharmaceutical Manufacturing Equipment System Model Quality Monitoring (Artifical Ground Truth Testing Alarm)\n",
    "\n",
    "This model quality monitoring with artificial ground truth for testing alarms was developed as part of the AAI-540 course, specifically aligned with Lab 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Host a trained machine learning model in Amazon SageMaker.  Monitor and detect machine learning model quality drift\n",
    "\n",
    "\n",
    "This notebook shows how to:\n",
    "- Host a machine learning model in Amazon SageMaker and capture inference requests, results, and metadata.\n",
    "- Generate a baseline of model quality and establish suggested constraints.\n",
    "- Monitor a live endpoint for violations against these constraints.\n",
    "- Generate CloudWatch Alarms on model quality drift.\n",
    "\n",
    "\n",
    "**Table of Contents** \n",
    "\n",
    "1. [Introduction](#intro)\n",
    "2. [Section 1 - Setup](#setup)\n",
    "3. [Section 2 - Deploy pre-trained model with data capture enabled](#deploy)\n",
    "5. [Section 3 - Generate baseline for model quality performance](#generate-baseline)\n",
    "6. [Section 4 - Setup continuous model monitoring to identify model quality drift](#analyze-model-quality-drift)\n",
    "7. [Section 5 - Analyze model quality CloudWatch metrics](#analyze-cloudwatch-metrics)\n",
    "8. [Clean up](#cleanup)\n",
    "\n",
    "\n",
    "\n",
    "## Introduction <a id='intro'></a>    \n",
    "\n",
    "Amazon SageMaker provides developers and data scientists with a comprehensive, fully-managed ML service that covers the entire ML workflow. SageMaker Model Monitor allows you to maintain high-quality ML models by automatically detecting inaccuracies in model predictions and identifying changes in independent variables.\n",
    "\n",
    "In this notebook, you will learn how to use SageMaker Model Monitor to assess the performance of the predictive maintenance model deployed for pharmaceutical manufacturing equipment. The model aims to reduce unplanned downtime and ensure regulatory compliance by predicting equipment failures.\n",
    "\n",
    "### Project Context\n",
    "\n",
    "The project uses the Predictive Maintenance Dataset from Kaggle, containing 124,000 entries of sensor readings and failure indicators. This dataset was chosen for its rich historical data, which supports the development of a robust predictive model. The Random Forest classifier used in this project is suitable for handling complex sensor data and balancing precision and recall, which is critical in predictive maintenance scenarios.\n",
    "\n",
    "The system aims to deploy a batch-mode model that provides daily or weekly predictions for scheduled maintenance, as opposed to real-time predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Setup <a id='setup'></a>\n",
    "\n",
    "In this section, you will import the necessary libraries, set up variables, and examine the data used to train the Random Forest model for predictive maintenance.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- **AWS Region**: The region used to host the predictive maintenance model.\n",
    "- **IAM Role**: The IAM role associated with this SageMaker notebook instance.\n",
    "- **S3 Bucket**: The S3 bucket storing training data, model artifacts, and captured inference data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "CPU times: user 1.59 s, sys: 250 ms, total: 1.84 s\n",
      "Wall time: 4.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import boto3\n",
    "from time import sleep\n",
    "from threading import Thread\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sagemaker import get_execution_role, session, Session, image_uris\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.processing import ProcessingJob\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 AWS region and  IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::807494057176:role/LabRole\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Get Execution role\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn:\", role)\n",
    "\n",
    "region = session.boto_region_name\n",
    "print(\"Region:\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 S3 bucket and prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket: sagemaker-us-east-1-807494057176\n",
      "Data Capture Path: s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/datacapture\n",
      "Ground Truth Path: s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/ground_truth_data/2024-10-22-23-47-31\n",
      "Report Path: s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/reports\n",
      "Monitor Image URI: 156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer\n"
     ]
    }
   ],
   "source": [
    "# Define the S3 bucket (default) and prefix for model monitoring\n",
    "bucket = session.default_bucket()  # Using the default SageMaker bucket\n",
    "prefix = \"predictive-maintenance-model-monitor\"\n",
    "\n",
    "# Define the S3 paths for data capture, ground truth, and reports\n",
    "data_capture_prefix = f\"{prefix}/datacapture\"\n",
    "s3_capture_upload_path = f\"s3://{bucket}/{data_capture_prefix}\"\n",
    "ground_truth_upload_path = f\"s3://{bucket}/{prefix}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "reports_prefix = f\"{prefix}/reports\"\n",
    "s3_report_path = f\"s3://{bucket}/{reports_prefix}\"\n",
    "\n",
    "# Model Monitor image URI\n",
    "monitor_image_uri = image_uris.retrieve(framework=\"model-monitor\", region=region)\n",
    "\n",
    "# Print setup details\n",
    "print(\"S3 Bucket:\", bucket)\n",
    "print(f\"Data Capture Path: {s3_capture_upload_path}\")\n",
    "print(f\"Ground Truth Path: {ground_truth_upload_path}\")\n",
    "print(f\"Report Path: {s3_report_path}\")\n",
    "print(f\"Monitor Image URI: {monitor_image_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Test access to the S3 bucket\n",
    "Verify that the notebook has the right permissions to access the specified S3 bucket. We will attempt to upload a simple test object to ensure that the notebook has the required permissions.\n",
    "\n",
    "If this command fails, it indicates that the data capture and model monitoring capabilities will not work correctly from this notebook. We set to resolve this issue by updating the role associated with this notebook instance to have \"s3:PutObject\" permissions and then retry the validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! You are all set to proceed.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "# Define the S3 bucket\n",
    "bucket = 'sagemaker-us-east-1-807494057176'\n",
    "\n",
    "# Define the local path to the test_data.csv file\n",
    "file_path = 'test_data.csv'\n",
    "\n",
    "# Upload the test_data.csv file to the specified S3 bucket\n",
    "try:\n",
    "    S3Uploader.upload(file_path, f\"s3://{bucket}/test_upload\")\n",
    "    print(\"Success! You are all set to proceed.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_path}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Deploy pre-trained model with data capture enabled <a id='deploy'></a>\n",
    "\n",
    "In this section, we will:\n",
    "1. Upload the pre-trained XGBoost model to the S3 bucket.\n",
    "2. Create an Amazon SageMaker Model.\n",
    "3. Deploy the model to a real-time endpoint with data capture enabled.\n",
    "4. Create a SageMaker Predictor object to invoke the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Upload the pre-trained model to S3\n",
    "\n",
    "In this step, you will upload a pre-trained XGBoost model to Amazon S3. This model was trained using the XGB Churn Prediction Notebook in SageMaker. You can replace this model with your own pre-trained model by specifying the correct `s3_key`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be used from: s3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/output/xgb-2024-10-22-13-55-23/xgb-2024-10-22-13-55-23/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Updated model S3 path\n",
    "model_s3_path = 's3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/output/xgb-2024-10-22-13-55-23/xgb-2024-10-22-13-55-23/output/model.tar.gz'\n",
    "\n",
    "print(f\"Model will be used from: {model_s3_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Create SageMaker Model entity\n",
    "\n",
    "This step involves creating an Amazon SageMaker model from the model file uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model entity created with name: sagemaker-xgboost-predictive-maintenance-2024-10-22-23-47-32\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker import image_uris\n",
    "\n",
    "# Define model details\n",
    "model_name = f\"sagemaker-xgboost-predictive-maintenance-{datetime.utcnow():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "# Use the XGBoost image URI from SageMaker\n",
    "image_uri = image_uris.retrieve(framework=\"xgboost\", version=\"1.7-1\", region=region)\n",
    "\n",
    "# Create the SageMaker Model entity\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_s3_path,  # Use the S3 path from 2.1\n",
    "    role=role,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "print(f\"Model entity created with name: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Deploy the model with data capture enabled.\n",
    "Now, deploy the SageMaker model to a real-time endpoint on a specific instance type, with data capture enabled to record endpoint invocations, predictions, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!Model deployed to endpoint: sagemaker-xgboost-endpoint-2024-10-22-23-47-32\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "# Define endpoint name\n",
    "endpoint_name = f\"sagemaker-xgboost-endpoint-{datetime.utcnow():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "# Configure data capture\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=\"s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/datacapture\"\n",
    ")\n",
    "\n",
    "# Deploy the model to an endpoint\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config\n",
    ")\n",
    "\n",
    "print(f\"Model deployed to endpoint: {endpoint_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Create the SageMaker Predictor object from the endpoint to be used for invoking the model\n",
    "The SageMaker Predictor object will be used to invoke the model and send data for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor created for endpoint: sagemaker-xgboost-endpoint-2024-10-22-23-47-32\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "# Create the Predictor object for invoking the model\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=session,\n",
    "    serializer=CSVSerializer()\n",
    ")\n",
    "\n",
    "print(f\"Predictor created for endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 3 - Generate a baseline for model quality performance <a id='generate-baseline'></a>\n",
    "\n",
    "In this section, we will invoke the endpoint created above using validation data. Predictions from the deployed model using this validation data will be used as a baseline dataset.  We will use SageMaker's Model Monitoring to execute a baseline job that computes model performance data, and suggest model quality constraints based on the baseline dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Execute predictions using the validation dataset. \n",
    "\n",
    "The deployed model returns the probability that an equipment failure will occur. We'll use a cutoff of 0.8 to classify a failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "failure_cutoff = 0.8\n",
    "validate_dataset = \"validation_with_predictions.csv\"\n",
    "limit = 200  # Need at least 200 samples to compute standard deviations\n",
    "i = 0\n",
    "with open(f\"{validate_dataset}\", \"w\") as baseline_file:\n",
    "    baseline_file.write(\"probability,prediction,label\\n\")  # our header\n",
    "    with open(\"validation_data.csv\", \"r\") as f:\n",
    "        for row in f:\n",
    "            (label, input_cols) = row.split(\",\", 1)\n",
    "            probability = float(predictor.predict(input_cols))\n",
    "            prediction = \"1\" if probability > failure_cutoff else \"0\"\n",
    "            baseline_file.write(f\"{probability},{prediction},{label}\\n\")\n",
    "            i += 1\n",
    "            if i > limit:\n",
    "                break\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            sleep(0.5)\n",
    "print()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Examine the predictions from the model\n",
    "\n",
    "To verify the predictions, we will display the first few rows of the baseline dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability,prediction,label\n",
      "0.9942198991775513,1,1\n",
      "0.947282075881958,1,1\n",
      "0.9391994476318359,1,1\n",
      "0.9983158111572266,1,1\n",
      "0.9875530004501343,1,1\n",
      "0.9990541338920593,1,1\n",
      "0.9955667853355408,1,1\n",
      "0.9984889030456543,1,1\n",
      "0.9997400641441345,1,1\n"
     ]
    }
   ],
   "source": [
    "!head validation_with_predictions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Upload the predictions as a baseline dataset.\n",
    "Next, upload the baseline dataset to S3 to be used for creating baseline statistics and constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/baselining/data\n",
      "Baseline results uri: s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/baselining/results\n",
      "Baseline dataset uploaded to: s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/baselining/data/validation_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "# Define the S3 prefixes for baseline data and results\n",
    "baseline_prefix = prefix + \"/baselining\"\n",
    "baseline_data_prefix = baseline_prefix + \"/data\"\n",
    "baseline_results_prefix = baseline_prefix + \"/results\"\n",
    "\n",
    "# Construct the S3 URIs\n",
    "baseline_data_uri = f\"s3://{bucket}/{baseline_data_prefix}\"\n",
    "baseline_results_uri = f\"s3://{bucket}/{baseline_results_prefix}\"\n",
    "\n",
    "print(f\"Baseline data uri: {baseline_data_uri}\")\n",
    "print(f\"Baseline results uri: {baseline_results_uri}\")\n",
    "\n",
    "# Upload the validation_with_predictions.csv file to S3\n",
    "baseline_dataset_uri = S3Uploader.upload(validate_dataset, baseline_data_uri)\n",
    "\n",
    "# Output the URI of the uploaded dataset\n",
    "print(f\"Baseline dataset uploaded to: {baseline_dataset_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Create a baselining job with validation dataset predictions\n",
    "Define the model quality monitoring object and execute the baseline job. This job will generate baseline statistics and constraints based on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name PM-xgb-model-baseline-job-2024-10-22-2352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................!Baseline job 'PM-xgb-model-baseline-job-2024-10-22-2352' has completed.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "# Create the ModelQualityMonitor object\n",
    "predictive_maintenance_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "# Define the name of the baseline job\n",
    "baseline_job_name = f\"PM-xgb-model-baseline-job-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "# Execute the baseline suggestion job\n",
    "job = predictive_maintenance_monitor.suggest_baseline(\n",
    "    job_name=baseline_job_name,\n",
    "    baseline_dataset=baseline_dataset_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    problem_type=\"BinaryClassification\",\n",
    "    inference_attribute=\"prediction\",\n",
    "    probability_attribute=\"probability\",\n",
    "    ground_truth_attribute=\"label\",\n",
    ")\n",
    "\n",
    "# Wait for the job to complete\n",
    "job.wait(logs=False)\n",
    "\n",
    "print(f\"Baseline job '{baseline_job_name}' has completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Explore the results of the baselining job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.1 View the metrics generated\n",
    "The baseline statistics and constraints files are already uploaded to the S3 location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                    0\n",
      "confusion_matrix.1.1                                                                              200\n",
      "confusion_matrix.1.0                                                                                1\n",
      "confusion_matrix.0.1                                                                                0\n",
      "confusion_matrix.0.0                                                                                0\n",
      "recall.value                                                                                 0.995025\n",
      "recall.standard_deviation                                                                     0.00239\n",
      "precision.value                                                                                   1.0\n",
      "precision.standard_deviation                                                                      0.0\n",
      "accuracy.value                                                                               0.995025\n",
      "accuracy.standard_deviation                                                                   0.00239\n",
      "recall_best_constant_classifier.value                                                             1.0\n",
      "recall_best_constant_classifier.standard_deviation                                                0.0\n",
      "precision_best_constant_classifier.value                                                          1.0\n",
      "precision_best_constant_classifier.standard_dev...                                                0.0\n",
      "accuracy_best_constant_classifier.value                                                           1.0\n",
      "accuracy_best_constant_classifier.standard_devi...                                                0.0\n",
      "true_positive_rate.value                                                                     0.995025\n",
      "true_positive_rate.standard_deviation                                                         0.00239\n",
      "true_negative_rate.value                                                                         None\n",
      "true_negative_rate.standard_deviation                                                            None\n",
      "false_positive_rate.value                                                                        None\n",
      "false_positive_rate.standard_deviation                                                           None\n",
      "false_negative_rate.value                                                                    0.004975\n",
      "false_negative_rate.standard_deviation                                                        0.00239\n",
      "receiver_operating_characteristic_curve.false_p...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "receiver_operating_characteristic_curve.true_po...  [0.0, 0.004975124378109453, 0.0099502487562189...\n",
      "precision_recall_curve.precisions                   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
      "precision_recall_curve.recalls                      [0.0, 0.004975124378109453, 0.0099502487562189...\n",
      "auc.value                                                                                         1.0\n",
      "auc.standard_deviation                                                                            0.0\n",
      "au_prc.value                                                                                      1.0\n",
      "au_prc.standard_deviation                                                                         0.0\n",
      "f0_5.value                                                                                   0.999001\n",
      "f0_5.standard_deviation                                                                       0.00048\n",
      "f1.value                                                                                     0.997506\n",
      "f1.standard_deviation                                                                        0.001199\n",
      "f2.value                                                                                     0.996016\n",
      "f2.standard_deviation                                                                        0.001915\n",
      "f0_5_best_constant_classifier.value                                                               1.0\n",
      "f0_5_best_constant_classifier.standard_deviation                                                  0.0\n",
      "f1_best_constant_classifier.value                                                                 1.0\n",
      "f1_best_constant_classifier.standard_deviation                                                    0.0\n",
      "f2_best_constant_classifier.value                                                                 1.0\n",
      "f2_best_constant_classifier.standard_deviation                                                    0.0\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the latest baseline job\n",
    "baseline_job = predictive_maintenance_monitor.latest_baselining_job\n",
    "\n",
    "# View the baseline metrics generated\n",
    "binary_metrics = baseline_job.baseline_statistics().body_dict[\"binary_classification_metrics\"]\n",
    "\n",
    "# Display the metrics in a structured format\n",
    "pd.set_option('display.max_rows', None)  # Optional: to view all rows\n",
    "print(pd.json_normalize(binary_metrics).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:\n",
    "\n",
    "### **Confusion Matrix**\n",
    "The confusion matrix indicates how well the model classified the validation data:\n",
    "\n",
    "- **confusion_matrix.1.1 (True Positives): 200**  \n",
    "  The model correctly identified 200 cases as \"failures\" (positive class), which represents accurate detection of equipment failures.\n",
    "\n",
    "- **confusion_matrix.1.0 (False Negatives): 1**  \n",
    "  The model missed 1 case of actual failure, misclassifying it as \"no failure.\" This suggests a low rate of missed failures.\n",
    "\n",
    "- **confusion_matrix.0.1 (False Positives): 0**  \n",
    "  No cases were mistakenly classified as failures when they weren’t. This indicates that the model didn't produce false alarms.\n",
    "\n",
    "- **confusion_matrix.0.0 (True Negatives): 0**  \n",
    "  No instances were correctly identified as \"no failure.\" This suggests that the validation set might have included mostly positive cases.\n",
    "\n",
    "### **Key Metrics**\n",
    "- **Recall.value: 0.995025**  \n",
    "  Recall measures the model's ability to identify actual failures. At ~99.5%, it indicates that the model is highly effective at detecting true failures, with a low chance of missing them.\n",
    "\n",
    "- **Recall.standard_deviation: 0.002447**  \n",
    "  This low standard deviation shows that the recall is consistent across the validation data.\n",
    "\n",
    "- **Precision.value: 1.0**  \n",
    "  Precision measures the accuracy of the model’s positive predictions. A precision of 1.0 means that every failure predicted by the model was indeed a failure, indicating no false alarms.\n",
    "\n",
    "- **Precision.standard_deviation: 0.0**  \n",
    "  The zero standard deviation suggests perfect consistency in the model’s positive predictions.\n",
    "\n",
    "- **Accuracy.value: 0.995025**  \n",
    "  Accuracy represents the proportion of correct predictions (both positive and negative). At ~99.5%, the model accurately predicts failures most of the time.\n",
    "\n",
    "- **Accuracy.standard_deviation: 0.002447**  \n",
    "  The accuracy is consistent across the validation data, with a low standard deviation.\n",
    "\n",
    "### **Other Metrics**\n",
    "- **AUC (Area Under the ROC Curve): 1.0**  \n",
    "  The AUC measures the model's ability to distinguish between classes. A perfect score of 1.0 suggests that the model differentiates failures from non-failures perfectly.\n",
    "\n",
    "- **AU PRC (Area Under the Precision-Recall Curve): 1.0**  \n",
    "  This metric measures the model’s performance in handling imbalanced datasets. A score of 1.0 indicates excellent precision-recall balance.\n",
    "\n",
    "- **F1 Score: 0.997506**  \n",
    "  The F1 score balances precision and recall. At ~99.7%, it reflects a strong balance between detecting failures and avoiding false positives.\n",
    "\n",
    "- **F2 Score: 0.996016**  \n",
    "  The F2 score places more weight on recall than precision, making it suitable for applications where missing failures is more costly. The model’s F2 score (~99.6%) suggests high effectiveness in this context.\n",
    "\n",
    "### **Interpretation**\n",
    "The results indicate a highly accurate and consistent model with minimal false negatives, making it well-suited for predictive maintenance. However, the presence of one false negative indicates a slight risk of missing a failure, which could be costly in this context. Despite that, the model achieves perfect precision, meaning no false positives occurred.\n",
    "\n",
    "The model demonstrates a strong ability to predict equipment failures with a high degree of reliability, which aligns well with the goals of minimizing unplanned downtime. The metrics suggest that the model is performing optimally, but continued monitoring and updates may be needed to maintain this level of performance over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.2 View the constraints generated\n",
    "Check the suggested constraints from the baseline job to ensure model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    threshold   comparison_operator\n",
      "recall               0.995025     LessThanThreshold\n",
      "precision                 1.0     LessThanThreshold\n",
      "accuracy             0.995025     LessThanThreshold\n",
      "true_positive_rate   0.995025     LessThanThreshold\n",
      "true_negative_rate       None     LessThanThreshold\n",
      "false_positive_rate      None  GreaterThanThreshold\n",
      "false_negative_rate  0.004975  GreaterThanThreshold\n",
      "auc                       1.0     LessThanThreshold\n",
      "f0_5                 0.999001     LessThanThreshold\n",
      "f1                   0.997506     LessThanThreshold\n",
      "f2                   0.996016     LessThanThreshold\n"
     ]
    }
   ],
   "source": [
    "# View the suggested constraints from the baseline job\n",
    "constraints = pd.DataFrame(baseline_job.suggested_constraints().body_dict[\"binary_classification_constraints\"])\n",
    "\n",
    "# Display the constraints in a structured format\n",
    "print(constraints.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, the model quality monitor suggested a constraint to ensure that the model’s F2 score does not drop below **0.996**. Some of the generated constraints, such as **precision**, may be a bit aggressive, as they will trigger alerts for any drops below **1.0**. It is advisable to adjust these constraints as needed before implementing them for ongoing monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 4 - Setup continuous model monitoring to identify model quality drift <a id='analyze-model-quality-drift'></a>\n",
    "\n",
    "In this section, we will set up a continuous model monitoring job that tracks the quality of the deployed predictive maintenance model against the baseline established in the previous section. This monitoring is crucial to ensure that the model's performance remains consistent and does not degrade over time.\n",
    "\n",
    "In addition to the baseline metrics and constraints, Amazon SageMaker Model Quality Monitoring requires two additional inputs:\n",
    "\n",
    "1. **Predictions Made by the Deployed Model Endpoint**: This data is automatically captured in S3, as data capture was enabled during deployment.\n",
    "2. **Ground Truth Data**: This represents the actual outcomes that occur after predictions are made, such as whether the equipment truly failed or not. Ground truth data is essential for measuring model accuracy over time. In the context of predictive maintenance, this could be obtained from maintenance records or operational logs indicating actual equipment failures.\n",
    "\n",
    "To simulate real-world conditions, we will generate synthetic ground truth data. This approach allows us to evaluate the monitoring system’s ability to detect deviations from the baseline performance and ensure that the model maintains its predictive accuracy in identifying equipment failures.\n",
    "\n",
    "The steps in this section include:\n",
    "1. **Generate Prediction Data**: We will simulate traffic by sending data to the model endpoint to capture predictions.\n",
    "2. **Generate Synthetic Ground Truth Data**: We will create synthetic ground truth data to compare with predictions.\n",
    "3. **Create a Monitoring Schedule**: We will set up the monitoring job to run at regular intervals, checking the model's predictions against the ground truth data.\n",
    "4. **View Captured Data**: We will examine the captured data in S3 to ensure it is properly logged and aligned with the ground truth.\n",
    "5. **Analyze Violations**: We will review potential violations compared to the baseline to detect any significant quality drift.\n",
    "\n",
    "By the end of this section, we will have established a continuous monitoring setup that ensures the predictive maintenance model maintains its quality and consistency, minimizing the risk of undetected equipment failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1 Generate prediction data for Model Quality  Monitoring\n",
    "\n",
    "We will begin by generating some artificial traffic to simulate inference requests to the model endpoint. The code cell below starts a thread that continuously sends data to the endpoint, triggering predictions and enabling data capture.\n",
    "\n",
    "It's important to note that we need to keep this process running to ensure that data is continuously sent to the endpoint, as the monitoring jobs depend on having enough data to process. If no traffic is detected, the monitoring jobs will be marked as \"Failed\" due to the lack of incoming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_endpoint(ep_name, file_name):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        i = 0\n",
    "        for row in f:\n",
    "            payload = row.rstrip(\"\\n\")\n",
    "            response = session.sagemaker_runtime_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType=\"text/csv\",\n",
    "                Body=payload,\n",
    "                InferenceId=str(i),  # unique ID per row\n",
    "            )[\"Body\"].read()\n",
    "            i += 1\n",
    "            sleep(1)\n",
    "\n",
    "\n",
    "def invoke_endpoint_forever():\n",
    "    while True:\n",
    "        try:\n",
    "            invoke_endpoint(endpoint_name, \"batch_data_noID.csv\")\n",
    "        except session.sagemaker_runtime_client.exceptions.ValidationError:\n",
    "            pass\n",
    "\n",
    "\n",
    "thread = Thread(target=invoke_endpoint_forever)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We are setting a new attribute, inferenceId, when invoking the endpoint. This attribute allows us to associate the prediction data with the corresponding ground truth data, ensuring accurate linkage during model quality evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 View captured data\n",
    "\n",
    "We will now list the data capture files stored in Amazon S3. These files are expected to be organized based on the time period in which each invocation occurred. The file path structure in S3 follows this format:\n",
    "\n",
    "`s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for captures to show up.................................\n",
      "Found Capture Files:\n",
      "s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/datacapture/sagemaker-xgboost-endpoint-2024-10-22-23-47-32/AllTraffic/2024/10/22/23/51-05-826-008bad9e-9650-4900-9765-1f73eeb6336c.jsonl\n",
      " s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/datacapture/sagemaker-xgboost-endpoint-2024-10-22-23-47-32/AllTraffic/2024/10/22/23/52-06-188-f7852649-01e1-4643-9bff-1798838df9dc.jsonl\n",
      " s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/datacapture/sagemaker-xgboost-endpoint-2024-10-22-23-47-32/AllTraffic/2024/10/22/23/57-52-827-0ec4dec3-0b95-4dd0-8630-c22be0058955.jsonl\n"
     ]
    }
   ],
   "source": [
    "print(\"Waiting for captures to show up\", end=\"\")\n",
    "for _ in range(120):\n",
    "    capture_files = sorted(S3Downloader.list(f\"{s3_capture_upload_path}/{endpoint_name}\"))\n",
    "    if capture_files:\n",
    "        capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")\n",
    "        capture_record = json.loads(capture_file[0])\n",
    "        if \"inferenceId\" in capture_record[\"eventMetadata\"]:\n",
    "            break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    sleep(1)\n",
    "print()\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files[-3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will examine the contents of one of the captured data files stored in S3. These files are formatted as Amazon SageMaker-specific JSON-lines, capturing both input and output data from the model endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"160599109,4526,0,744,10,245268,8,8,3\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"0.9904484152793884\\n\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"8e1e6286-a4bf-4d26-91f6-95c9cdbb0f35\",\"inferenceId\":\"56\",\"inferenceTime\":\"2024-10-22T23:58:51Z\"},\"eventVersion\":\"0\"}\n",
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"241881004,3362,0,70,6,113180,15,15,0\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"0.9877150058746338\\n\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"6e349854-fac2-4251-8e51-e564a8baf1c0\",\"inferenceId\":\"57\",\"inferenceTime\":\"2024-10-22T23:58:52Z\"},\"eventVersion\":\"0\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(capture_file[-3:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of a single line are shown below in a formatted JSON file for clearer observation.\n",
    "\n",
    "Key components to note:\n",
    "- **`endpointInput`**: Contains information about the input data sent to the endpoint, including its content type, mode, data, and encoding.\n",
    "- **`endpointOutput`**: Includes the model's output, such as content type, mode, the prediction data, and encoding.\n",
    "- **`eventMetadata`**: Provides metadata about the event, including **`eventId`**, **`inferenceId`**, and **`inferenceTime`**.\n",
    "- **`eventVersion`**: Indicates the version of the event format.\n",
    "\n",
    "Notice the **`inferenceId`** attribute set during the `invoke_endpoint` call. This attribute is used to link prediction data with the corresponding ground truth data. If **`inferenceId`** is unavailable, **`eventId`** will be used instead for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captureData\": {\n",
      "    \"endpointInput\": {\n",
      "      \"observedContentType\": \"text/csv\",\n",
      "      \"mode\": \"INPUT\",\n",
      "      \"data\": \"64506368,0,0,0,8,296181,0,0,0\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    },\n",
      "    \"endpointOutput\": {\n",
      "      \"observedContentType\": \"text/csv; charset=utf-8\",\n",
      "      \"mode\": \"OUTPUT\",\n",
      "      \"data\": \"0.08915980160236359\\n\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    }\n",
      "  },\n",
      "  \"eventMetadata\": {\n",
      "    \"eventId\": \"4d056182-e5df-4a00-96cd-191e104e2239\",\n",
      "    \"inferenceId\": \"0\",\n",
      "    \"inferenceTime\": \"2024-10-22T23:57:52Z\"\n",
      "  },\n",
      "  \"eventVersion\": \"0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(capture_record, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Generate synthetic ground truth\n",
    "\n",
    "Now, we will generate synthetic ground truth data to simulate the actual outcomes of equipment conditions. This is crucial, as the model quality monitoring job requires ground truth data to merge with the captured prediction data. Without it, the monitoring job will fail.\n",
    "\n",
    "The synthetic ground truth will assign a label of \"1\" (indicating failure) 70% of the time, mimicking a scenario with a higher rate of failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def ground_truth_with_id(inference_id):\n",
    "    random.seed(inference_id)  # to get consistent results\n",
    "    rand = random.random()\n",
    "    return {\n",
    "        \"groundTruthData\": {\n",
    "            \"data\": \"1\" if rand < 0.7 else \"0\",  # randomly generate positive labels 70% of the time\n",
    "            \"encoding\": \"CSV\",\n",
    "        },\n",
    "        \"eventMetadata\": {\n",
    "            \"eventId\": str(inference_id),\n",
    "        },\n",
    "        \"eventVersion\": \"0\",\n",
    "    }\n",
    "\n",
    "\n",
    "def upload_ground_truth(records, upload_time):\n",
    "    fake_records = [json.dumps(r) for r in records]\n",
    "    data_to_upload = \"\\n\".join(fake_records)\n",
    "    target_s3_uri = f\"{ground_truth_upload_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    print(f\"Uploading {len(fake_records)} records to\", target_s3_uri)\n",
    "    S3Uploader.upload_string_as_file_body(data_to_upload, target_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 334 records to s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/ground_truth_data/2024-10-22-23-47-31/2024/10/22/23/5856.jsonl\n",
      "Uploading 334 records to s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/ground_truth_data/2024-10-22-23-47-31/2024/10/23/00/5857.jsonl\n"
     ]
    }
   ],
   "source": [
    "NUM_GROUND_TRUTH_RECORDS = 334  # 334 are the number of rows in data we're sending for inference\n",
    "\n",
    "\n",
    "def generate_fake_ground_truth_forever():\n",
    "    j = 0\n",
    "    while True:\n",
    "        fake_records = [ground_truth_with_id(i) for i in range(NUM_GROUND_TRUTH_RECORDS)]\n",
    "        upload_ground_truth(fake_records, datetime.utcnow())\n",
    "        j = (j + 1) % 5\n",
    "        sleep(60 * 60)  # do this once an hour\n",
    "\n",
    "\n",
    "gt_thread = Thread(target=generate_fake_ground_truth_forever)\n",
    "gt_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Create a monitoring schedule\n",
    "\n",
    "With the baseline metrics established and synthetic ground truth data being generated, we can now set up a monitoring schedule. This schedule will trigger a model quality monitoring job at regular intervals, checking for deviations in model performance.\n",
    "\n",
    "The monitoring job will compare the captured predictions against the ground truth data and generate alerts if the model's performance drops below the baseline thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring Schedule Name: PM-xgb-predictive-maintenance-schedule-2024-10-22-2358\n"
     ]
    }
   ],
   "source": [
    "# Define the monitoring schedule name\n",
    "monitor_schedule_name = f\"PM-xgb-predictive-maintenance-schedule-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "# Output the name for verification\n",
    "print(f\"Monitoring Schedule Name: {monitor_schedule_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure the monitoring schedule, we need to define how to interpret the model's output. The endpoint in this notebook outputs predictions in CSV format, where the first column (index 0) contains the probability of failure.\n",
    "\n",
    "For this predictive maintenance model, we set a cutoff of 0.5 to classify the prediction as a positive label. In this case, a probability above 0.5 indicates a failure prediction, while a value below 0.5 indicates no failure.\n",
    "\n",
    "This configuration ensures that the monitoring schedule accurately interprets the endpoint’s output for model quality assessments and drift detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Input Created: <sagemaker.model_monitor.model_monitoring.EndpointInput object at 0x7f31ab8821d0>\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import EndpointInput\n",
    "\n",
    "# Create an EndpointInput object\n",
    "endpoint_input = EndpointInput(\n",
    "    endpoint_name=predictor.endpoint_name,\n",
    "    probability_attribute=\"0\",  # Index for the probability output (e.g., first column)\n",
    "    probability_threshold_attribute=0.5,  # Threshold for binary classification (e.g., 0.5)\n",
    "    destination=\"/opt/ml/processing/input_data\"\n",
    ")\n",
    "\n",
    "# Print for verification\n",
    "print(f\"Endpoint Input Created: {endpoint_input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: PM-xgb-predictive-maintenance-schedule-2024-10-22-2358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring schedule created: None\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "# Create the monitoring schedule to execute every hour\n",
    "response = predictive_maintenance_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=monitor_schedule_name,\n",
    "    endpoint_input=endpoint_input,\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    problem_type=\"BinaryClassification\",\n",
    "    ground_truth_input=ground_truth_upload_path,\n",
    "    constraints=baseline_job.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")\n",
    "\n",
    "# Print the response for verification\n",
    "print(\"Monitoring schedule created:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring Schedule Details:\n",
      "{'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:807494057176:monitoring-schedule/PM-xgb-predictive-maintenance-schedule-2024-10-22-2358', 'MonitoringScheduleName': 'PM-xgb-predictive-maintenance-schedule-2024-10-22-2358', 'MonitoringScheduleStatus': 'Pending', 'MonitoringType': 'ModelQuality', 'CreationTime': datetime.datetime(2024, 10, 22, 23, 58, 57, 562000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 10, 22, 23, 58, 57, 635000, tzinfo=tzlocal()), 'MonitoringScheduleConfig': {'ScheduleConfig': {'ScheduleExpression': 'cron(0 * ? * * *)'}, 'MonitoringJobDefinitionName': 'model-quality-job-definition-2024-10-22-23-58-56-974', 'MonitoringType': 'ModelQuality'}, 'EndpointName': 'sagemaker-xgboost-endpoint-2024-10-22-23-47-32', 'ResponseMetadata': {'RequestId': '28dd1c12-bfbb-438a-9aed-010e82cf031a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '28dd1c12-bfbb-438a-9aed-010e82cf031a', 'content-type': 'application/x-amz-json-1.1', 'content-length': '632', 'date': 'Tue, 22 Oct 2024 23:58:57 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Describe the monitoring schedule\n",
    "schedule_description = predictive_maintenance_monitor.describe_schedule()\n",
    "\n",
    "# Print the schedule details for verification\n",
    "print(\"Monitoring Schedule Details:\")\n",
    "print(schedule_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Examine monitoring schedule executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.model_monitor.model_monitoring:No executions found for schedule. monitoring_schedule_name: PM-xgb-predictive-maintenance-schedule-2024-10-22-2358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Executions:\n"
     ]
    }
   ],
   "source": [
    "# List the executions for the created monitoring schedule\n",
    "executions = predictive_maintenance_monitor.list_executions()\n",
    "\n",
    "# Print the list of executions for verification\n",
    "print(\"List of Executions:\")\n",
    "for execution in executions:\n",
    "    print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for first execution.....................................\n",
      "Execution found!\n"
     ]
    }
   ],
   "source": [
    "# Wait for the first execution of the monitoring_schedule\n",
    "print(\"Waiting for first execution\", end=\"\")\n",
    "while True:\n",
    "    execution = predictive_maintenance_monitor.describe_schedule().get(\n",
    "        \"LastMonitoringExecutionSummary\"\n",
    "    )\n",
    "    if execution:\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    sleep(10)\n",
    "print()\n",
    "print(\"Execution found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ProcessingInputs': [{'InputName': 'groundtruth_input_1',\n",
       "   'AppManaged': False,\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/ground_truth_data/2024-10-22-23-47-31/2024/10/22/23',\n",
       "    'LocalPath': '/opt/ml/processing/groundtruth/2024/10/22/23',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}},\n",
       "  {'InputName': 'endpoint_input_1',\n",
       "   'AppManaged': False,\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/datacapture/sagemaker-xgboost-endpoint-2024-10-22-23-47-32/AllTraffic/2024/10/22/23',\n",
       "    'LocalPath': '/opt/ml/processing/input_data/sagemaker-xgboost-endpoint-2024-10-22-23-47-32/AllTraffic/2024/10/22/23',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}}],\n",
       " 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'result',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/baselining/results/merge',\n",
       "     'LocalPath': '/opt/ml/processing/output',\n",
       "     'S3UploadMode': 'EndOfJob'},\n",
       "    'AppManaged': False}]},\n",
       " 'ProcessingJobName': 'groundtruth-merge-202410230000-c9dc23b38db6393a3ca9aa0c',\n",
       " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
       "   'InstanceType': 'ml.m5.xlarge',\n",
       "   'VolumeSizeInGB': 20}},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 1800},\n",
       " 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-groundtruth-merger'},\n",
       " 'Environment': {'dataset_format': '{\"sagemakerCaptureJson\":{\"captureIndexNames\":null}}',\n",
       "  'dataset_source': '/opt/ml/processing/input_data',\n",
       "  'end_time': '2024-10-23T00:00:00Z',\n",
       "  'ground_truth_source': '/opt/ml/processing/groundtruth',\n",
       "  'monitoring_input_type': 'ENDPOINT_INPUT',\n",
       "  'output_path': '/opt/ml/processing/output',\n",
       "  'start_time': '2024-10-22T23:00:00Z'},\n",
       " 'RoleArn': 'arn:aws:iam::807494057176:role/LabRole',\n",
       " 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:processing-job/groundtruth-merge-202410230000-c9dc23b38db6393a3ca9aa0c',\n",
       " 'ProcessingJobStatus': 'InProgress',\n",
       " 'LastModifiedTime': datetime.datetime(2024, 10, 23, 0, 7, 23, 714000, tzinfo=tzlocal()),\n",
       " 'CreationTime': datetime.datetime(2024, 10, 23, 0, 7, 23, 67000, tzinfo=tzlocal()),\n",
       " 'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:807494057176:monitoring-schedule/PM-xgb-predictive-maintenance-schedule-2024-10-22-2358',\n",
       " 'ResponseMetadata': {'RequestId': 'b3686dc3-5ae1-4255-b38b-9147ab484435',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b3686dc3-5ae1-4255-b38b-9147ab484435',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '2271',\n",
       "   'date': 'Wed, 23 Oct 2024 00:07:41 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while not executions:\n",
    "    executions = predictive_maintenance_monitor.list_executions()\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    sleep(10)\n",
    "latest_execution = executions[-1]\n",
    "latest_execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect a Specific Execution (Latest Execution)\n",
    "\n",
    "In the previous step, we retrieved the latest execution of the monitoring schedule. Here’s an overview of the potential terminal states and what they indicate:\n",
    "\n",
    "- **Completed**: The monitoring execution finished successfully, with no constraint violations detected in the report.\n",
    "- **CompletedWithViolations**: The execution completed, but constraint violations were found, indicating possible quality drift.\n",
    "- **Failed**: The monitoring execution failed, potentially due to client-side errors (e.g., incorrect role permissions) or infrastructure issues. To identify the cause, we need to review the `FailureReason` and `ExitMessage`.\n",
    "- **Stopped**: The job was either stopped manually or exceeded the maximum runtime.\n",
    "\n",
    "This inspection allows us to understand the current status of the monitoring job and respond accordingly:\n",
    "\n",
    "- If **violations** are detected, we should review the report for further details.\n",
    "- If the job **failed**, we need to investigate based on the provided failure reason and exit message.\n",
    "- If the job was **stopped**, we should verify whether this was intentional or due to a runtime limit.\n",
    "\n",
    "This approach ensures that we can effectively manage and maintain model quality, taking corrective action when necessary to keep the model performing within acceptable limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for execution to finish!\n",
      "groundtruth-merge-202410230000-c9dc23b38db6393a3ca9aa0c job status: Completed\n",
      "groundtruth-merge-202410230000-c9dc23b38db6393a3ca9aa0c job exit message, if any: None\n",
      "groundtruth-merge-202410230000-c9dc23b38db6393a3ca9aa0c job failure reason, if any: None\n",
      "Execution status is: CompletedWithViolations\n",
      "{'MonitoringScheduleName': 'PM-xgb-predictive-maintenance-schedule-2024-10-22-2358', 'ScheduledTime': datetime.datetime(2024, 10, 23, 0, 0, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2024, 10, 23, 0, 5, 10, 289000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 10, 23, 0, 21, 58, 674000, tzinfo=tzlocal()), 'MonitoringExecutionStatus': 'CompletedWithViolations', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:807494057176:processing-job/model-quality-monitoring-202410230000-c9dc23b38db6393a3ca9aa0c', 'EndpointName': 'sagemaker-xgboost-endpoint-2024-10-22-23-47-32'}\n",
      "====STOP==== \n",
      " No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\n"
     ]
    }
   ],
   "source": [
    "status = execution[\"MonitoringExecutionStatus\"]\n",
    "\n",
    "while status in [\"Pending\", \"InProgress\"]:\n",
    "    print(\"Waiting for execution to finish\", end=\"\")\n",
    "    latest_execution.wait(logs=False)\n",
    "    latest_job = latest_execution.describe()\n",
    "    print()\n",
    "    print(f\"{latest_job['ProcessingJobName']} job status:\", latest_job[\"ProcessingJobStatus\"])\n",
    "    print(\n",
    "        f\"{latest_job['ProcessingJobName']} job exit message, if any:\",\n",
    "        latest_job.get(\"ExitMessage\"),\n",
    "    )\n",
    "    print(\n",
    "        f\"{latest_job['ProcessingJobName']} job failure reason, if any:\",\n",
    "        latest_job.get(\"FailureReason\"),\n",
    "    )\n",
    "    sleep(\n",
    "        30\n",
    "    )  # model quality executions consist of two Processing jobs, wait for second job to start\n",
    "    latest_execution = predictive_maintenance_monitor.list_executions()[-1]\n",
    "    execution = predictive_maintenance_monitor.describe_schedule()[\"LastMonitoringExecutionSummary\"]\n",
    "    status = execution[\"MonitoringExecutionStatus\"]\n",
    "\n",
    "print(\"Execution status is:\", status)\n",
    "\n",
    "if status != \"Completed\":\n",
    "    print(execution)\n",
    "    print(\n",
    "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Uri: s3://sagemaker-us-east-1-807494057176/predictive-maintenance-model-monitor/baselining/results/sagemaker-xgboost-endpoint-2024-10-22-23-47-32/PM-xgb-predictive-maintenance-schedule-2024-10-22-2358/2024/10/23/00\n"
     ]
    }
   ],
   "source": [
    "latest_execution = predictive_maintenance_monitor.list_executions()[-1]\n",
    "report_uri = latest_execution.describe()[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\n",
    "    \"S3Uri\"\n",
    "]\n",
    "print(\"Report Uri:\", report_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 View violations generated by monitoring schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any violations were detected during the monitoring execution, they are recorded in the violations report generated by Amazon SageMaker Model Monitor. These reports are uploaded to the specified S3 location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constraint_check_type</th>\n",
       "      <th>description</th>\n",
       "      <th>metric_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LessThanThreshold</td>\n",
       "      <td>Metric auc with 0.4617049617049617 was LessThanThreshold '1.0'</td>\n",
       "      <td>auc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LessThanThreshold</td>\n",
       "      <td>Metric precision with 0.7391304347826086 was LessThanThreshold '1.0'</td>\n",
       "      <td>precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LessThanThreshold</td>\n",
       "      <td>Metric truePositiveRate with 0.18681318681318682 was LessThanThreshold '0.9950248756218906'</td>\n",
       "      <td>truePositiveRate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LessThanThreshold</td>\n",
       "      <td>Metric f1 with 0.2982456140350877 was LessThanThreshold '0.9975062344139651'</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LessThanThreshold</td>\n",
       "      <td>Metric accuracy with 0.3548387096774194 was LessThanThreshold '0.9950248756218906'</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GreaterThanThreshold</td>\n",
       "      <td>Metric falseNegativeRate with 0.8131868131868132 was GreaterThanThreshold '0.00497512437810943'</td>\n",
       "      <td>falseNegativeRate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LessThanThreshold</td>\n",
       "      <td>Metric recall with 0.18681318681318682 was LessThanThreshold '0.9950248756218906'</td>\n",
       "      <td>recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LessThanThreshold</td>\n",
       "      <td>Metric f2 with 0.2196382428940568 was LessThanThreshold '0.9960159362549802'</td>\n",
       "      <td>f2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  constraint_check_type  \\\n",
       "0     LessThanThreshold   \n",
       "1     LessThanThreshold   \n",
       "2     LessThanThreshold   \n",
       "3     LessThanThreshold   \n",
       "4     LessThanThreshold   \n",
       "5  GreaterThanThreshold   \n",
       "6     LessThanThreshold   \n",
       "7     LessThanThreshold   \n",
       "\n",
       "                                                                                       description  \\\n",
       "0                                   Metric auc with 0.4617049617049617 was LessThanThreshold '1.0'   \n",
       "1                             Metric precision with 0.7391304347826086 was LessThanThreshold '1.0'   \n",
       "2      Metric truePositiveRate with 0.18681318681318682 was LessThanThreshold '0.9950248756218906'   \n",
       "3                     Metric f1 with 0.2982456140350877 was LessThanThreshold '0.9975062344139651'   \n",
       "4               Metric accuracy with 0.3548387096774194 was LessThanThreshold '0.9950248756218906'   \n",
       "5  Metric falseNegativeRate with 0.8131868131868132 was GreaterThanThreshold '0.00497512437810943'   \n",
       "6                Metric recall with 0.18681318681318682 was LessThanThreshold '0.9950248756218906'   \n",
       "7                     Metric f2 with 0.2196382428940568 was LessThanThreshold '0.9960159362549802'   \n",
       "\n",
       "         metric_name  \n",
       "0                auc  \n",
       "1          precision  \n",
       "2   truePositiveRate  \n",
       "3                 f1  \n",
       "4           accuracy  \n",
       "5  falseNegativeRate  \n",
       "6             recall  \n",
       "7                 f2  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = None\n",
    "violations = latest_execution.constraint_violations().body_dict[\"violations\"]\n",
    "violations_df = pd.json_normalize(violations)\n",
    "violations_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "- The **F2 score** is lower than the threshold set during baseline creation, indicating that the model's recall-focused performance has dropped.\n",
    "- The **AUC**, **precision**, **truePositiveRate**, and **recall** also show a decline, suggesting a decrease in the model's ability to distinguish between classes.\n",
    "- The **falseNegativeRate** is higher than expected, indicating that the model is missing more failure predictions than anticipated.\n",
    "\n",
    "#### Next Steps\n",
    "- **Investigate the cause** of these violations, which could be due to changes in data distribution, model performance degradation, or other factors.\n",
    "- **Retrain or fine-tune the model** if significant drifts are observed.\n",
    "- **Adjust baseline thresholds** if necessary, ensuring that they are set realistically to balance precision and recall without triggering unnecessary alerts.\n",
    "\n",
    "Monitoring these violations helps maintain model performance, ensuring that predictive maintenance remains effective and reliable over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5 - Analyze model quality CloudWatch metrics <a id='analyze-cloudwatch-metrics'></a> \n",
    "\n",
    "In addition to generating violation reports, the monitoring schedule also emits CloudWatch metrics that provide detailed insights into the model's performance over time. By tracking these metrics, we can set up CloudWatch alarms to automatically alert us when the model’s performance drifts from baseline thresholds. This allows us to take remedial actions like model retraining or updating the training dataset to maintain model quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 List the CW metrics generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CloudWatch client\n",
    "cw_client = boto3.Session().client(\"cloudwatch\")\n",
    "\n",
    "namespace = \"aws/sagemaker/Endpoints/model-metrics\"\n",
    "\n",
    "cw_dimensions = [\n",
    "    {\"Name\": \"Endpoint\", \"Value\": endpoint_name},\n",
    "    {\"Name\": \"MonitoringSchedule\", \"Value\": monitor_schedule_name},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall\n",
      "total_number_of_violations\n",
      "f0_5_best_constant_classifier\n",
      "f1_best_constant_classifier\n",
      "f2\n",
      "f0_5\n",
      "precision_best_constant_classifier\n",
      "accuracy\n",
      "auc\n",
      "true_positive_rate\n",
      "au_prc\n",
      "recall_best_constant_classifier\n",
      "f1\n",
      "precision\n",
      "f2_best_constant_classifier\n",
      "true_negative_rate\n",
      "accuracy_best_constant_classifier\n",
      "false_negative_rate\n",
      "false_positive_rate\n"
     ]
    }
   ],
   "source": [
    "# List metrics through the pagination interface\n",
    "paginator = cw_client.get_paginator(\"list_metrics\")\n",
    "\n",
    "for response in paginator.paginate(Dimensions=cw_dimensions, Namespace=namespace):\n",
    "    model_quality_metrics = response[\"Metrics\"]\n",
    "    for metric in model_quality_metrics:\n",
    "        print(metric[\"MetricName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Create a CloudWatch Alarm\n",
    "\n",
    "Based on the metrics emitted by the model quality monitoring schedule, we can set up a CloudWatch alarm to alert us when the F2 score falls below the threshold suggested by the baseline constraints. This ensures we are promptly notified about potential model performance degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3e03841b-f00d-40ce-8d51-d5185439a10f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '3e03841b-f00d-40ce-8d51-d5185439a10f',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '214',\n",
       "   'date': 'Wed, 23 Oct 2024 01:01:49 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarm_name = \"MODEL_QUALITY_F2_SCORE\"\n",
    "alarm_desc = (\n",
    "    \"Trigger an CloudWatch alarm when the f2 score drifts away from the baseline constraints\"\n",
    ")\n",
    "mdoel_quality_f2_drift_threshold = (\n",
    "    0.5  ##Setting this threshold purposefully low to see the alarm quickly.\n",
    ")\n",
    "metric_name = \"f2\"\n",
    "namespace = \"aws/sagemaker/Endpoints/model-metrics\"\n",
    "\n",
    "cw_client.put_metric_alarm(\n",
    "    AlarmName=alarm_name,\n",
    "    AlarmDescription=alarm_desc,\n",
    "    ActionsEnabled=True,\n",
    "    MetricName=metric_name,\n",
    "    Namespace=namespace,\n",
    "    Statistic=\"Average\",\n",
    "    Dimensions=[\n",
    "        {\"Name\": \"Endpoint\", \"Value\": endpoint_name},\n",
    "        {\"Name\": \"MonitoringSchedule\", \"Value\": monitor_schedule_name},\n",
    "    ],\n",
    "    Period=600,\n",
    "    EvaluationPeriods=1,\n",
    "    DatapointsToAlarm=1,\n",
    "    Threshold=mdoel_quality_f2_drift_threshold,\n",
    "    ComparisonOperator=\"LessThanOrEqualToThreshold\",\n",
    "    TreatMissingData=\"breaching\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5.3 Validation\n",
    "In a few minutes, you should see a CloudWatch alarm created. The alarm will first be in \"Insufficient Data\" state and moves into \"Alert\" state. This can be verified in the CloudWatch console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the CW Alarm is generated, you can decide on what actions you want to take on these alerts.  A possible action could be updating the training data an retraining the model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up <a id='cleanup'></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can keep your endpoint running to continue capturing data. If you do not plan to collect more data or use this endpoint further, you should delete the endpoint to avoid incurring additional charges. Note that deleting your endpoint does not delete the data that was captured during the model invocations. That data persists in Amazon S3 until you delete it yourself.\n",
    "\n",
    "But before that, you need to delete the schedule first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictive_maintenance_monitor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictive_maintenance_monitor\u001b[49m\u001b[38;5;241m.\u001b[39mdelete_monitoring_schedule()\n\u001b[1;32m      2\u001b[0m sleep(\u001b[38;5;241m60\u001b[39m)  \u001b[38;5;66;03m# actually wait for the deletion\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictive_maintenance_monitor' is not defined"
     ]
    }
   ],
   "source": [
    "predictive_maintenance_monitor.delete_monitoring_schedule()\n",
    "sleep(60)  # actually wait for the deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mdelete_model()\n\u001b[1;32m      2\u001b[0m predictor\u001b[38;5;241m.\u001b[39mdelete_endpoint()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/sagemaker_model_monitor|model_quality|model_quality_churn_sdk.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
