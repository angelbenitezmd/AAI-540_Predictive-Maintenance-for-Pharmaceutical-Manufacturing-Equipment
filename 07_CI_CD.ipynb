{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50337931-e753-4cc2-b143-a38d6cc93584",
   "metadata": {},
   "source": [
    "# CI/CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c720132-904c-4c45-ae1e-02a41fe35d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat\n",
    ")\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.functions import JsonGet, Join\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "from sagemaker.workflow.pipeline import PipelineExperimentConfig\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d1abc-a445-4d24-92b7-cd4e58ac92c4",
   "metadata": {},
   "source": [
    "### Setup Files and Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d7ed0e9-324b-432a-bb24-084967399647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up data files for account 691334595165 in region us-east-1\n",
      "Target bucket: sagemaker-us-east-1-691334595165\n",
      "\n",
      "Uploading train_data.csv to s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/train_data.csv\n",
      "✓ Successfully uploaded train_data.csv\n",
      "✓ Verified file at s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/train_data.csv\n",
      "\n",
      "Uploading test_data.csv to s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/test_data.csv\n",
      "✓ Successfully uploaded test_data.csv\n",
      "✓ Verified file at s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/test_data.csv\n",
      "\n",
      "Uploading model.tar.gz to s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/output/xgb-2024-10-22-13-55-23/output/model.tar.gz\n",
      "✓ Successfully uploaded model.tar.gz\n",
      "✓ Verified file at s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/output/xgb-2024-10-22-13-55-23/output/model.tar.gz\n",
      "\n",
      "Checking all required S3 paths...\n",
      "✓ Found s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/train_data.csv\n",
      "✓ Found s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/test_data.csv\n",
      "✓ Found s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/output/xgb-2024-10-22-13-55-23/output/model.tar.gz\n",
      "\n",
      "All required files are in place. You can proceed with the pipeline.\n"
     ]
    }
   ],
   "source": [
    "# Upload Required Data Files\n",
    "import boto3\n",
    "import os\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def upload_required_data():\n",
    "    \"\"\"Upload required data files to the appropriate S3 locations\"\"\"\n",
    "    # Setup AWS clients\n",
    "    session = boto3.Session()\n",
    "    s3 = session.client('s3')\n",
    "    account_id = session.client('sts').get_caller_identity()['Account']\n",
    "    region = session.region_name\n",
    "    bucket = f\"sagemaker-{region}-{account_id}\"\n",
    "    \n",
    "    print(f\"Setting up data files for account {account_id} in region {region}\")\n",
    "    print(f\"Target bucket: {bucket}\")\n",
    "    \n",
    "    # Define required files and their S3 paths\n",
    "    required_files = {\n",
    "        'train_data.csv': 'predictive-maintenance-feature-store/train_data.csv',\n",
    "        'test_data.csv': 'predictive-maintenance-feature-store/test_data.csv',\n",
    "        'model.tar.gz': 'predictive-maintenance-feature-store/output/xgb-2024-10-22-13-55-23/output/model.tar.gz'\n",
    "    }\n",
    "    \n",
    "    # Check and upload each file\n",
    "    for local_file, s3_path in required_files.items():\n",
    "        if os.path.exists(local_file):\n",
    "            try:\n",
    "                print(f\"\\nUploading {local_file} to s3://{bucket}/{s3_path}\")\n",
    "                s3.upload_file(local_file, bucket, s3_path)\n",
    "                print(f\"✓ Successfully uploaded {local_file}\")\n",
    "                \n",
    "                # Verify upload\n",
    "                try:\n",
    "                    s3.head_object(Bucket=bucket, Key=s3_path)\n",
    "                    print(f\"✓ Verified file at s3://{bucket}/{s3_path}\")\n",
    "                except ClientError:\n",
    "                    print(f\"✗ Could not verify file at s3://{bucket}/{s3_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error uploading {local_file}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"\\n✗ Local file {local_file} not found\")\n",
    "            print(f\"Please ensure {local_file} is in the current directory\")\n",
    "    \n",
    "    print(\"\\nChecking all required S3 paths...\")\n",
    "    all_files_present = True\n",
    "    for _, s3_path in required_files.items():\n",
    "        try:\n",
    "            s3.head_object(Bucket=bucket, Key=s3_path)\n",
    "            print(f\"✓ Found s3://{bucket}/{s3_path}\")\n",
    "        except ClientError:\n",
    "            print(f\"✗ Missing s3://{bucket}/{s3_path}\")\n",
    "            all_files_present = False\n",
    "    \n",
    "    if all_files_present:\n",
    "        print(\"\\nAll required files are in place. You can proceed with the pipeline.\")\n",
    "    else:\n",
    "        print(\"\\nSome files are missing. Please ensure all required files are present before proceeding.\")\n",
    "        print(\"\\nRequired files:\")\n",
    "        for _, s3_path in required_files.items():\n",
    "            print(f\"- s3://{bucket}/{s3_path}\")\n",
    "\n",
    "# Run upload\n",
    "upload_required_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca47e01f-3a44-4e12-b877-1d93c8a67833",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Settings:\n",
      "Account ID: 691334595165\n",
      "Region: us-east-1\n",
      "Default bucket: sagemaker-us-east-1-691334595165\n"
     ]
    }
   ],
   "source": [
    "# Configure Account-Specific Settings\n",
    "def get_account_specific_settings():\n",
    "    \"\"\"Get account-specific settings that need to be configured\"\"\"\n",
    "    session = Session()\n",
    "    account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "    region = session.boto_region_name\n",
    "    \n",
    "    # Construct the default bucket name\n",
    "    default_bucket = f\"sagemaker-{region}-{account_id}\"\n",
    "    \n",
    "    print(\"Account Settings:\")\n",
    "    print(f\"Account ID: {account_id}\")\n",
    "    print(f\"Region: {region}\")\n",
    "    print(f\"Default bucket: {default_bucket}\")\n",
    "    \n",
    "    return default_bucket, region\n",
    "\n",
    "# Get account-specific settings\n",
    "default_bucket, region = get_account_specific_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "156185c5-c561-4bbe-aa50-445a3629cb87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking required files...\n",
      "✓ Found train_data at s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/train_data.csv\n",
      "✓ Found test_data at s3://sagemaker-us-east-1-691334595165/predictive-maintenance-feature-store/test_data.csv\n",
      "✓ Found preprocess_script at code/preprocess.py\n",
      "✓ Found evaluate_script at code/evaluate.py\n",
      "\n",
      "Data Statistics:\n",
      "Train data shape: (152657, 10)\n",
      "\n",
      "Train data columns:\n",
      "['0', '215630672', '55', '0.1', '52', '6', '407438', '0.2', '0.3', '7']\n",
      "\n",
      "Test data shape: (37746, 11)\n",
      "\n",
      "Test data columns:\n",
      "['2015-07-01', '1', '203011379', '16', '56', '5', '10', '277481', '10.1', '10.2', '946']\n",
      "\n",
      "First few rows of training data:\n",
      "   0  215630672    55  0.1  52   6  407438  0.2  0.3  7\n",
      "0  1   11487214     0    0   0  16  412767    4    4  0\n",
      "1  1  149265550  2024    0   1  50  251894    0    0  0\n",
      "2  1  236294969     0    0   1  10  262375    0    0  0\n",
      "3  1  133207556     0    0  14  10  247231   55   55  0\n",
      "4  1  180004303  2767    0  18   7  197868   29   29  0\n",
      "\n",
      "Could not identify target column. Available columns are listed above.\n",
      "\n",
      "All required files are in place. Proceeding with pipeline setup.\n"
     ]
    }
   ],
   "source": [
    "def verify_required_files():\n",
    "    \"\"\"Verify that all required files are present in S3 with proper data examination\"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    required_files = {\n",
    "        \"train_data\": f\"predictive-maintenance-feature-store/train_data.csv\",\n",
    "        \"test_data\": f\"predictive-maintenance-feature-store/test_data.csv\",\n",
    "        \"preprocess_script\": \"code/preprocess.py\",\n",
    "        \"evaluate_script\": \"code/evaluate.py\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\nChecking required files...\")\n",
    "    missing_files = []\n",
    "    \n",
    "    # Check S3 files\n",
    "    for file_type, file_path in required_files.items():\n",
    "        if file_type in [\"train_data\", \"test_data\"]:\n",
    "            try:\n",
    "                s3_client.head_object(Bucket=default_bucket, Key=file_path)\n",
    "                print(f\"✓ Found {file_type} at s3://{default_bucket}/{file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Missing {file_type} at s3://{default_bucket}/{file_path}\")\n",
    "                missing_files.append(file_path)\n",
    "    \n",
    "    # Check local code files\n",
    "    for file_type, file_path in required_files.items():\n",
    "        if file_type.endswith('_script'):\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"✗ Missing {file_type} at {file_path}\")\n",
    "                missing_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"✓ Found {file_type} at {file_path}\")\n",
    "    \n",
    "    # Print data shape info if files exist\n",
    "    try:\n",
    "        train_data = pd.read_csv(f\"s3://{default_bucket}/predictive-maintenance-feature-store/train_data.csv\")\n",
    "        test_data = pd.read_csv(f\"s3://{default_bucket}/predictive-maintenance-feature-store/test_data.csv\")\n",
    "        \n",
    "        print(\"\\nData Statistics:\")\n",
    "        print(f\"Train data shape: {train_data.shape}\")\n",
    "        print(\"\\nTrain data columns:\")\n",
    "        print(train_data.columns.tolist())\n",
    "        \n",
    "        print(f\"\\nTest data shape: {test_data.shape}\")\n",
    "        print(\"\\nTest data columns:\")\n",
    "        print(test_data.columns.tolist())\n",
    "        \n",
    "        # Sample of data\n",
    "        print(\"\\nFirst few rows of training data:\")\n",
    "        print(train_data.head())\n",
    "        \n",
    "        # If we find the actual target column name, show its distribution\n",
    "        potential_target_columns = ['target', 'label', 'class', 'failure', 'Status']\n",
    "        target_col = None\n",
    "        for col in potential_target_columns:\n",
    "            if col in train_data.columns:\n",
    "                target_col = col\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError examining data files: {str(e)}\")\n",
    "    \n",
    "    return len(missing_files) == 0, missing_files\n",
    "\n",
    "# Verify files\n",
    "files_ok, missing_files = verify_required_files()\n",
    "if not files_ok:\n",
    "    print(\"\\nMissing required files. Please ensure the following files are in place:\")\n",
    "    for file_path in missing_files:\n",
    "        print(f\"- {file_path}\")\n",
    "    print(\"\\nPlease copy these files to the correct locations before proceeding.\")\n",
    "else:\n",
    "    print(\"\\nAll required files are in place. Proceeding with pipeline setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad010c2-b339-4368-84e2-f7190285a2f5",
   "metadata": {},
   "source": [
    "### Modify for your bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa9f449c-2781-4b46-ba66-f061913188a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup SageMaker session and role\n",
    "session = Session()\n",
    "pipeline_session = PipelineSession()\n",
    "role = get_execution_role()\n",
    "region = session.boto_region_name\n",
    "#default_bucket = \"sagemaker-us-east-1-807494057176\"\n",
    "default_bucket = \"sagemaker-us-east-1-691334595165\"\n",
    "model_package_group_name = \"PMPredictiveMaintenanceModels\"\n",
    "#model_s3_path = \"s3://sagemaker-us-east-1-807494057176/predictive-maintenance-feature-store/output/xgb-2024-10-22-13-55-23/output/model.tar.gz\"\n",
    "model_s3_path = f\"s3://{default_bucket}/predictive-maintenance-feature-store/output/xgb-2024-10-22-13-55-23/output/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b71fb036-47a6-41ad-a125-6f676e80d0ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define pipeline parameters\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8027fb65-58a4-4d33-bd84-30d6a8e85215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#input_data = ParameterString(\n",
    "    #name=\"InputData\",\n",
    "    #default_value=f\"s3://{default_bucket}/predictive-maintenance-model-monitor/datacapture/sagemaker-xgboost-endpoint-2024-10-22-23-47-32/\"\n",
    "#)\n",
    "\n",
    "#input_data = ParameterString(\n",
    "#    name=\"InputData\",\n",
    "#    default_value=f\"s3://{default_bucket}/predictive-maintenance-model-monitor/datacapture/validation_with_predictions.csv\"\n",
    "#)\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=f\"s3://{default_bucket}/predictive-maintenance-feature-store/\"  # Directory with your CSV files\n",
    ")\n",
    "\n",
    "quality_threshold = ParameterFloat(\n",
    "    name=\"QualityThreshold\",\n",
    "    default_value=0.996\n",
    ")\n",
    "base_output_path = f\"s3://{default_bucket}/PMPredictiveMaintenancePipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b2f5d78-69a1-40f7-aab2-5af30841fb13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "# Get container images\n",
    "xgb_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.7-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d49f06e2-57d0-46eb-b3ca-5856f9aa9a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create preprocessing step\n",
    "processor = ScriptProcessor(\n",
    "    image_uri=xgb_image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"pm-preprocess\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Cell 6 - Create Preprocessing Step\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessPMData\",\n",
    "    processor=processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_data,\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/train\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[base_output_path, \"preprocessing_output\", \"train\"]\n",
    "            )\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/test\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[base_output_path, \"preprocessing_output\", \"test\"]\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    code=\"code/preprocess.py\",\n",
    "    job_arguments=[\n",
    "        \"--input-path\", \"/opt/ml/processing/input\",\n",
    "        \"--output-path\", \"/opt/ml/processing\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30806eb4-fbdd-4722-94ba-cca418677817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create XGBoost estimator\n",
    "xgb_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgb_image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    output_path=f\"{base_output_path}/models\",\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bfd393ff-6efd-46e7-9d47-818466c3e433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_train = TrainingStep(\n",
    "    name=\"TrainPMModel\",\n",
    "    estimator=xgb_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[0].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluatePMModel\",\n",
    "    processor=processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[1].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[base_output_path, ExecutionVariables.PIPELINE_EXECUTION_ID, \"EvaluatePMModel\", \"output\"]\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    code=\"code/evaluate.py\",\n",
    "    job_arguments=[\n",
    "        \"--model-path\", \"/opt/ml/processing/model\",\n",
    "        \"--test-path\", \"/opt/ml/processing/test\",\n",
    "        \"--output-path\", \"/opt/ml/processing/evaluation\"\n",
    "    ],\n",
    "    property_files=[evaluation_report]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ab3dd8e-c3e0-4088-b3e7-b4473a14e8a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation S3 URI: {'Std:Join': {'On': '/', 'Values': [{'Get': 'Steps.EvaluatePMModel.ProcessingOutputConfig.Outputs[0].S3Output.S3Uri'}, 'evaluation.json']}}\n"
     ]
    }
   ],
   "source": [
    "# Create model metrics matching your monitoring metrics\n",
    "try:\n",
    "    evaluation_s3_uri = Join(\n",
    "        on=\"/\",\n",
    "        values=[\n",
    "            step_eval.properties.ProcessingOutputConfig.Outputs[0].S3Output.S3Uri,\n",
    "            \"evaluation.json\"\n",
    "        ]\n",
    "    )\n",
    "    print(f\"\\nEvaluation S3 URI: {evaluation_s3_uri.expr}\")\n",
    "    \n",
    "    model_metrics = ModelMetrics(\n",
    "        model_statistics=MetricsSource(\n",
    "            s3_uri=evaluation_s3_uri,\n",
    "            content_type=\"application/json\"\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error creating model metrics: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Create register model step\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterPMModel\",\n",
    "    estimator=xgb_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n",
    "# Create condition step\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.f2.value\"\n",
    "    ),\n",
    "    right=quality_threshold\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckModelQuality\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8593ab9-557b-4344-b8a0-c3fb72998d94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:691334595165:pipeline/PMPredictiveMaintenancePipeline',\n",
       " 'ResponseMetadata': {'RequestId': '0882072b-84a3-4831-bb4d-5041d13be907',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0882072b-84a3-4831-bb4d-5041d13be907',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '99',\n",
       "   'date': 'Sat, 26 Oct 2024 19:59:36 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline definition config\n",
    "pipeline_definition_config = PipelineDefinitionConfig(\n",
    "    use_custom_job_prefix=True\n",
    ")\n",
    "\n",
    "# make the pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=\"PMPredictiveMaintenancePipeline\",\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        quality_threshold\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval],\n",
    "    sagemaker_session=pipeline_session #\n",
    ")\n",
    "\n",
    "pipeline.upsert(\n",
    "    role_arn=role,\n",
    "    description=\"CI/CD pipeline for predictive maintenance model with quality monitoring\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c34e5-4f0c-4bb3-9d2d-5e75684ed2f5",
   "metadata": {},
   "source": [
    "## Start the pipeline execution with initial model\n",
    "Code should run if you have access to the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4739597-a0f8-410a-af7e-b0015689a960",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline started. Waiting for completion...\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 - Start Pipeline Execution\n",
    "execution = pipeline.start(\n",
    "    parameters={\n",
    "        \"ProcessingInstanceCount\": 1,\n",
    "        \"TrainingInstanceType\": \"ml.m5.xlarge\",\n",
    "        \"ModelApprovalStatus\": \"PendingManualApproval\",\n",
    "        \"QualityThreshold\": 0.996\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Pipeline started. Waiting for completion...\")\n",
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743490d3-1a63-4aaf-9951-9cf63e80510a",
   "metadata": {},
   "source": [
    "### Analyze execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fecd5d2f-542a-4662-8646-e77209d3833c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline execution steps and their status:\n",
      "\n",
      "Step: EvaluatePMModel\n",
      "Status: Succeeded\n",
      "\n",
      "Step: TrainPMModel\n",
      "Status: Succeeded\n",
      "\n",
      "Step: PreprocessPMData\n",
      "Status: Succeeded\n",
      "\n",
      "Full execution details:\n",
      "Status: Succeeded\n"
     ]
    }
   ],
   "source": [
    "# Cell 12 - Check Execution Status\n",
    "execution_steps = execution.list_steps()\n",
    "print(\"Pipeline execution steps and their status:\")\n",
    "for step in execution_steps:\n",
    "    print(f\"\\nStep: {step['StepName']}\")\n",
    "    print(f\"Status: {step['StepStatus']}\")\n",
    "    if step['StepStatus'] == 'Failed':\n",
    "        print(f\"Failure Reason: {step.get('FailureReason', 'No failure reason provided')}\")\n",
    "\n",
    "execution_details = execution.describe()\n",
    "print(\"\\nFull execution details:\")\n",
    "print(f\"Status: {execution_details['PipelineExecutionStatus']}\")\n",
    "if execution_details['PipelineExecutionStatus'] == 'Failed':\n",
    "    print(f\"Failure Reason: {execution_details.get('FailureReason', 'No failure reason provided')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab605c-8f61-4c4a-bcac-1eca2d751e92",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4fffeac2-35a9-4491-9dba-106717805d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# New Hyperparameters\n",
    "improved_hyperparameters = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": 100,  # Increased from 50\n",
    "    \"max_depth\": 6,    # Increased from 5\n",
    "    \"eta\": 0.1,        # Decreased from 0.2 for more careful learning\n",
    "    \"gamma\": 3,        # Decreased from 4\n",
    "    \"min_child_weight\": 4,  # Decreased from 6\n",
    "    \"subsample\": 0.8,      # Increased from 0.7\n",
    "    \"colsample_bytree\": 0.8,  # Added feature sampling\n",
    "    \"scale_pos_weight\": 2,    # Added to handle class imbalance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a64cadaf-8c07-433b-a248-06fcb6eb5269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# improved estimator\n",
    "improved_xgb_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgb_image_uri,  # Reuse the image_uri from your existing pipeline\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    output_path=f\"{base_output_path}/improved_models\",\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "improved_xgb_estimator.set_hyperparameters(**improved_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "caae43f7-a869-49b4-96e9-f01c5efe4ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# improved training step\n",
    "step_train_improved = TrainingStep(\n",
    "    name=\"TrainImprovedPMModel\",\n",
    "    estimator=improved_xgb_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[0].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "81c690d9-bef6-4e22-a3f5-ac8b3674a0ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluatePMModel\",\n",
    "    processor=processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train_improved.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[1].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    base_output_path,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"evaluation\"\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    code=\"code/evaluate.py\",\n",
    "    job_arguments=[\n",
    "        \"--model-path\", \"/opt/ml/processing/model\",\n",
    "        \"--test-path\", \"/opt/ml/processing/test\",\n",
    "        \"--output-path\", \"/opt/ml/processing/evaluation\"\n",
    "    ],\n",
    "    property_files=[evaluation_report]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0f8cca9-d396-4d05-8c6c-e252eabf7d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create model metrics\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                step_eval.properties.ProcessingOutputConfig.Outputs[0].S3Output.S3Uri,\n",
    "                \"evaluation.json\"\n",
    "            ]\n",
    "        ),\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cell [Next] - Update register model step\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterImprovedPMModel\",\n",
    "    estimator=improved_xgb_estimator,\n",
    "    model_data=step_train_improved.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e904ffe-b79f-428e-a16d-c6aedacabc6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update condition step with correct path\n",
    "condition_better = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.f1.value\"\n",
    "    ),\n",
    "    right=0.85\n",
    ")\n",
    "\n",
    "step_cond_improved = ConditionStep(\n",
    "    name=\"CheckImprovedModelQuality\",\n",
    "    conditions=[condition_better],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506c52b3-a49e-4daf-8350-4566aeb7346f",
   "metadata": {},
   "source": [
    "## Improved Pipeline Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b9176e5-f585-45a9-9358-3f7fbf4d9740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:691334595165:pipeline/ImprovedPMPredictiveMaintenancePipeline',\n",
       " 'ResponseMetadata': {'RequestId': '5a791873-b15f-4a7b-bca8-b3e6d5b318c9',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '5a791873-b15f-4a7b-bca8-b3e6d5b318c9',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '107',\n",
       "   'date': 'Sat, 26 Oct 2024 20:10:27 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_pipeline = Pipeline(\n",
    "    name=\"ImprovedPMPredictiveMaintenancePipeline\",\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        quality_threshold\n",
    "    ],\n",
    "    steps=[step_process, step_train_improved, step_eval, step_cond_improved],\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "improved_pipeline.upsert(\n",
    "    role_arn=role,\n",
    "    description=\"Improved CI/CD pipeline for predictive maintenance model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d246563e-4bc0-4dfe-8912-8e63f862054d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting improved pipeline execution...\n",
      "Waiting for improved pipeline execution to complete...\n"
     ]
    }
   ],
   "source": [
    "# execute\n",
    "print(\"Starting improved pipeline execution...\")\n",
    "improved_execution = improved_pipeline.start(\n",
    "    parameters={\n",
    "        \"ProcessingInstanceCount\": 1,\n",
    "        \"TrainingInstanceType\": \"ml.m5.xlarge\",\n",
    "        \"ModelApprovalStatus\": \"PendingManualApproval\",\n",
    "        \"QualityThreshold\": 0.85\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Waiting for improved pipeline execution to complete...\")\n",
    "improved_execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077ef1a-5ebc-4f6d-a4ea-d8e94a7ff455",
   "metadata": {},
   "source": [
    "## Analyze Improved Model Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2e81c53-c01e-4f6b-9eaa-8960c8555153",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline execution steps and their status:\n",
      "\n",
      "Step: RegisterImprovedPMModel-RegisterModel\n",
      "Status: Succeeded\n",
      "\n",
      "Step: CheckImprovedModelQuality\n",
      "Status: Succeeded\n",
      "\n",
      "Step: EvaluatePMModel\n",
      "Status: Succeeded\n",
      "\n",
      "Step: TrainImprovedPMModel\n",
      "Status: Succeeded\n",
      "\n",
      "Step: PreprocessPMData\n",
      "Status: Succeeded\n",
      "\n",
      "Full execution details:\n",
      "Status: Succeeded\n"
     ]
    }
   ],
   "source": [
    "def check_pipeline_execution(execution):\n",
    "    steps = execution.list_steps()\n",
    "    print(\"\\nPipeline execution steps and their status:\")\n",
    "    \n",
    "    for step in steps:\n",
    "        print(f\"\\nStep: {step['StepName']}\")\n",
    "        print(f\"Status: {step['StepStatus']}\")\n",
    "        \n",
    "        # Print more details for failed steps\n",
    "        if step['StepStatus'] == 'Failed':\n",
    "            print(f\"Failure Reason: {step.get('FailureReason', 'No failure reason provided')}\")\n",
    "            \n",
    "            # Get the CloudWatch logs for the failed step\n",
    "            if 'Metadata' in step and 'ProcessingJob' in step['Metadata']:\n",
    "                job_name = step['Metadata']['ProcessingJob']['Arn'].split('/')[-1]\n",
    "                print(f\"\\nCloudWatch Logs for failed job {job_name}:\")\n",
    "                logs_client = boto3.client('logs')\n",
    "                log_group = f\"/aws/sagemaker/ProcessingJobs\"\n",
    "                \n",
    "                try:\n",
    "                    log_streams = logs_client.describe_log_streams(\n",
    "                        logGroupName=log_group,\n",
    "                        logStreamNamePrefix=job_name\n",
    "                    )\n",
    "                    \n",
    "                    for stream in log_streams['logStreams']:\n",
    "                        logs = logs_client.get_log_events(\n",
    "                            logGroupName=log_group,\n",
    "                            logStreamName=stream['logStreamName']\n",
    "                        )\n",
    "                        \n",
    "                        print(\"\\nLog events:\")\n",
    "                        for event in logs['events']:\n",
    "                            print(event['message'])\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not retrieve logs: {str(e)}\")\n",
    "    \n",
    "    execution_details = execution.describe()\n",
    "    print(\"\\nFull execution details:\")\n",
    "    print(f\"Status: {execution_details['PipelineExecutionStatus']}\")\n",
    "    if execution_details['PipelineExecutionStatus'] == 'Failed':\n",
    "        print(f\"Failure Reason: {execution_details.get('FailureReason', 'No failure reason provided')}\")\n",
    "check_pipeline_execution(improved_execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53fa6e-f54a-4eb5-bf22-124196f97639",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35225fd1-ca80-441b-94ac-96a65a76ae99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting logs for initial pipeline:\n",
      "\n",
      "Retrieving logs for evaluation job: pipelines-prno9jsypm5c-EvaluatePMModel-PpOc5KWVLn\n",
      "\n",
      "Logs from stream: pipelines-prno9jsypm5c-EvaluatePMModel-PpOc5KWVLn/algo-1-1729973268\n",
      "=== Starting Enhanced Evaluation ===\n",
      "Output path: /opt/ml/processing/evaluation\n",
      "Calculating metrics...\n",
      "Saving metrics...\n",
      "Writing metrics to: /opt/ml/processing/evaluation/evaluation.json\n",
      "['evaluation.json']\n",
      "Evaluation completed successfully\n",
      "Metrics summary:\n",
      "{\n",
      "  \"binary_classification_metrics\": {\n",
      "    \"accuracy\": {\n",
      "      \"value\": 0.9681034254377832,\n",
      "      \"standard_deviation\": 0.1757247367145952\n",
      "    },\n",
      "    \"precision\": {\n",
      "      \"value\": 0.9546529562982005,\n",
      "      \"standard_deviation\": 0.0\n",
      "    },\n",
      "    \"recall\": {\n",
      "      \"value\": 0.9829539438856538,\n",
      "      \"standard_deviation\": 0.0\n",
      "    },\n",
      "    \"f1\": {\n",
      "      \"value\": 0.9685967657798643,\n",
      "      \"standard_deviation\": 0.0\n",
      "    },\n",
      "    \"auc_roc\": {\n",
      "      \"value\": 0.9958300909694157,\n",
      "      \"standard_deviation\": 0.0\n",
      "    }\n",
      "  }\n",
      "\n",
      "Getting logs for improved pipeline:\n",
      "\n",
      "Retrieving logs for evaluation job: pipelines-0alha7bwdcpc-EvaluatePMModel-QlLs0KLJZB\n",
      "\n",
      "Logs from stream: pipelines-0alha7bwdcpc-EvaluatePMModel-QlLs0KLJZB/algo-1-1729973965\n",
      "=== Starting Enhanced Evaluation ===\n",
      "Output path: /opt/ml/processing/evaluation\n",
      "Calculating metrics...\n",
      "Saving metrics...\n",
      "Writing metrics to: /opt/ml/processing/evaluation/evaluation.json\n",
      "['evaluation.json']\n",
      "Evaluation completed successfully\n",
      "Metrics summary:\n",
      "{\n",
      "  \"binary_classification_metrics\": {\n",
      "    \"accuracy\": {\n",
      "      \"value\": 0.9716533764272658,\n",
      "      \"standard_deviation\": 0.1659611174485155\n",
      "    },\n",
      "    \"precision\": {\n",
      "      \"value\": 0.9512306289881495,\n",
      "      \"standard_deviation\": 0.0\n",
      "    },\n",
      "    \"recall\": {\n",
      "      \"value\": 0.9943356273160402,\n",
      "      \"standard_deviation\": 0.0\n",
      "    },\n",
      "    \"f1\": {\n",
      "      \"value\": 0.9723056216999688,\n",
      "      \"standard_deviation\": 0.0\n",
      "    },\n",
      "    \"auc_roc\": {\n",
      "      \"value\": 0.9976000489937459,\n",
      "      \"standard_deviation\": 0.0\n",
      "    }\n",
      "  }\n"
     ]
    }
   ],
   "source": [
    "def get_evaluation_logs(execution):\n",
    "    \"\"\"Retrieve CloudWatch logs for the evaluation step\"\"\"\n",
    "    try:\n",
    "        # Get the evaluation step details\n",
    "        steps = execution.list_steps()\n",
    "        eval_step = next((step for step in steps if step['StepName'] == 'EvaluatePMModel'), None)\n",
    "        \n",
    "        if eval_step and 'Metadata' in eval_step:\n",
    "            job_name = eval_step['Metadata'].get('ProcessingJob', {}).get('Arn', '').split('/')[-1]\n",
    "            \n",
    "            if job_name:\n",
    "                print(f\"\\nRetrieving logs for evaluation job: {job_name}\")\n",
    "                logs_client = boto3.client('logs')\n",
    "                \n",
    "                # Get log streams\n",
    "                response = logs_client.describe_log_streams(\n",
    "                    logGroupName=\"/aws/sagemaker/ProcessingJobs\",\n",
    "                    logStreamNamePrefix=job_name\n",
    "                )\n",
    "                \n",
    "                # Get logs from each stream\n",
    "                for stream in response.get('logStreams', []):\n",
    "                    print(f\"\\nLogs from stream: {stream['logStreamName']}\")\n",
    "                    logs = logs_client.get_log_events(\n",
    "                        logGroupName=\"/aws/sagemaker/ProcessingJobs\",\n",
    "                        logStreamName=stream['logStreamName']\n",
    "                    )\n",
    "                    \n",
    "                    for event in logs['events']:\n",
    "                        if 'metrics' in event['message'].lower() or 'evaluation' in event['message'].lower():\n",
    "                            print(event['message'])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving logs: {str(e)}\")\n",
    "\n",
    "print(\"\\nGetting logs for initial pipeline:\")\n",
    "get_evaluation_logs(execution)\n",
    "\n",
    "print(\"\\nGetting logs for improved pipeline:\")\n",
    "get_evaluation_logs(improved_execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c646b5-3414-4ff5-93eb-6c1e92648bfc",
   "metadata": {},
   "source": [
    "## Metrics & Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "070340cd-514d-40a0-b410-d48d2a654a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def track_model_comparison(execution_initial, execution_improved):\n",
    "    \"\"\"Track and store model comparisons in SageMaker and CloudWatch\"\"\"\n",
    "    \n",
    "    def get_eval_metrics(execution):\n",
    "        \"\"\"Get evaluation metrics with improved error handling and debugging\"\"\"\n",
    "        try:\n",
    "            # Get execution ID and print it for verification\n",
    "            execution_details = execution.describe()\n",
    "            execution_id = execution_details['PipelineExecutionArn'].split('/')[-1]\n",
    "            print(f\"\\nProcessing execution ID: {execution_id}\")\n",
    "            \n",
    "            # Get evaluation step details\n",
    "            eval_step = next(step for step in execution.list_steps() \n",
    "                           if step['StepName'] == 'EvaluatePMModel')\n",
    "            job_name = eval_step['Metadata']['ProcessingJob']['Arn'].split('/')[-1]\n",
    "            print(f\"Processing job name: {job_name}\")\n",
    "            \n",
    "            # Get the evaluation output\n",
    "            s3_client = boto3.client('s3')\n",
    "            \n",
    "            # Check multiple possible S3 paths for evaluation results\n",
    "            possible_paths = [\n",
    "                f\"{base_output_path}/{execution_id}/EvaluatePMModel/output\",\n",
    "                f\"{base_output_path}/{execution_id}/evaluation\",\n",
    "                f\"{base_output_path}/{execution_id}/EvaluatePMModel\",\n",
    "                f\"{base_output_path}/{execution_id}\"\n",
    "            ]\n",
    "            \n",
    "            print(\"\\nSearching for evaluation.json in the following paths:\")\n",
    "            for s3_base_path in possible_paths:\n",
    "                print(f\"Checking path: {s3_base_path}\")\n",
    "                \n",
    "                # Remove the s3:// prefix and bucket name from the path\n",
    "                prefix = s3_base_path.replace(f\"s3://{default_bucket}/\", \"\")\n",
    "                \n",
    "                # List objects in this path\n",
    "                response = s3_client.list_objects_v2(\n",
    "                    Bucket=default_bucket,\n",
    "                    Prefix=prefix\n",
    "                )\n",
    "                \n",
    "                # Print all objects found in this path\n",
    "                if 'Contents' in response:\n",
    "                    print(\"\\nFiles found in this path:\")\n",
    "                    for obj in response['Contents']:\n",
    "                        print(f\"- {obj['Key']}\")\n",
    "                        if obj['Key'].endswith('evaluation.json'):\n",
    "                            eval_key = obj['Key']\n",
    "                            print(f\"\\nFound evaluation.json at: {eval_key}\")\n",
    "                            \n",
    "                            # Get and parse the evaluation file\n",
    "                            response = s3_client.get_object(Bucket=default_bucket, Key=eval_key)\n",
    "                            metrics = json.loads(response['Body'].read().decode('utf-8'))\n",
    "                            return metrics['binary_classification_metrics'], job_name\n",
    "                else:\n",
    "                    print(\"No files found in this path\")\n",
    "            \n",
    "            # If we get here, we didn't find the file\n",
    "            raise FileNotFoundError(\n",
    "                f\"Could not find evaluation.json in any of the expected paths. \"\n",
    "                f\"Please check the S3 bucket {default_bucket} manually.\"\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing execution {execution_id}:\")\n",
    "            print(f\"Error type: {type(e).__name__}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "            \n",
    "            # Print step details for debugging\n",
    "            print(\"\\nStep details:\")\n",
    "            for step in execution.list_steps():\n",
    "                print(f\"\\nStep Name: {step['StepName']}\")\n",
    "                print(f\"Step Status: {step['StepStatus']}\")\n",
    "                if 'Metadata' in step:\n",
    "                    print(\"Metadata:\", json.dumps(step['Metadata'], indent=2))\n",
    "            raise\n",
    "\n",
    "    try:\n",
    "        # Get metrics for both models\n",
    "        print(\"\\nProcessing initial model metrics:\")\n",
    "        initial_metrics, initial_job = get_eval_metrics(execution_initial)\n",
    "        \n",
    "        print(\"\\nProcessing improved model metrics:\")\n",
    "        improved_metrics, improved_job = get_eval_metrics(execution_improved)\n",
    "        \n",
    "        # Create CloudWatch metrics\n",
    "        cloudwatch = boto3.client('cloudwatch')\n",
    "        \n",
    "        # Put metrics in CloudWatch\n",
    "        def put_comparison_metrics(metrics, model_version):\n",
    "            for metric_name, metric_data in metrics.items():\n",
    "                if isinstance(metric_data, dict) and 'value' in metric_data:\n",
    "                    cloudwatch.put_metric_data(\n",
    "                        Namespace='CustomModelMetrics',\n",
    "                        MetricData=[{\n",
    "                            'MetricName': metric_name,\n",
    "                            'Value': metric_data['value'],\n",
    "                            'Unit': 'None',\n",
    "                            'Dimensions': [\n",
    "                                {'Name': 'ModelVersion', 'Value': model_version}\n",
    "                            ]\n",
    "                        }]\n",
    "                    )\n",
    "\n",
    "        put_comparison_metrics(initial_metrics, 'Initial')\n",
    "        put_comparison_metrics(improved_metrics, 'Improved')\n",
    "        \n",
    "        # Create comparison dashboard\n",
    "        dashboard_name = f\"ModelComparison-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "        dashboard_body = {\n",
    "            \"widgets\": [\n",
    "                {\n",
    "                    \"type\": \"metric\",\n",
    "                    \"properties\": {\n",
    "                        \"metrics\": [\n",
    "                            [\"CustomModelMetrics\", \"accuracy\", \"ModelVersion\", \"Initial\"],\n",
    "                            [\".\", \".\", \".\", \"Improved\"],\n",
    "                            [\".\", \"f1\", \".\", \"Initial\"],\n",
    "                            [\".\", \".\", \".\", \"Improved\"],\n",
    "                            [\".\", \"precision\", \".\", \"Initial\"],\n",
    "                            [\".\", \".\", \".\", \"Improved\"],\n",
    "                            [\".\", \"recall\", \".\", \"Initial\"],\n",
    "                            [\".\", \".\", \".\", \"Improved\"]\n",
    "                        ],\n",
    "                        \"view\": \"bar\",\n",
    "                        \"region\": sagemaker.Session().boto_region_name,\n",
    "                        \"title\": \"Model Performance Comparison\",\n",
    "                        \"period\": 300\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        cloudwatch.put_dashboard(\n",
    "            DashboardName=dashboard_name,\n",
    "            DashboardBody=json.dumps(dashboard_body)\n",
    "        )\n",
    "        \n",
    "        # Print URLs and comparison\n",
    "        region = sagemaker.Session().boto_region_name\n",
    "        print(\"\\nModel Comparison Resources:\")\n",
    "        print(f\"\\n1. CloudWatch Dashboard:\")\n",
    "        print(f\"https://{region}.console.aws.amazon.com/cloudwatch/home?region={region}#dashboards:name={dashboard_name}\")\n",
    "        \n",
    "        print(f\"\\n2. Processing Jobs (Evaluation Results):\")\n",
    "        print(f\"Initial model: https://{region}.console.aws.amazon.com/sagemaker/home?region={region}#/processing-jobs/{initial_job}\")\n",
    "        print(f\"Improved model: https://{region}.console.aws.amazon.com/sagemaker/home?region={region}#/processing-jobs/{improved_job}\")\n",
    "        \n",
    "        # Print metric comparison table\n",
    "        print(\"\\nMetrics Comparison:\")\n",
    "        print(\"\\nMetric      Initial    Improved   Difference\")\n",
    "        print(\"-\" * 45)\n",
    "        for metric in ['accuracy', 'precision', 'recall', 'f1', 'auc_roc']:\n",
    "            if metric in initial_metrics and metric in improved_metrics:\n",
    "                initial = initial_metrics[metric]['value']\n",
    "                improved = improved_metrics[metric]['value']\n",
    "                diff = improved - initial\n",
    "                print(f\"{metric:<10} {initial:.4f}    {improved:.4f}    {diff:+.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'dashboard_name': dashboard_name,\n",
    "            'initial_metrics': initial_metrics,\n",
    "            'improved_metrics': improved_metrics,\n",
    "            'initial_job': initial_job,\n",
    "            'improved_job': improved_job\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in model comparison:\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f970c1c4-e40d-4de8-be3a-46c73372ecc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing initial model metrics:\n",
      "\n",
      "Processing execution ID: prno9jsypm5c\n",
      "Processing job name: pipelines-prno9jsypm5c-EvaluatePMModel-PpOc5KWVLn\n",
      "\n",
      "Searching for evaluation.json in the following paths:\n",
      "Checking path: s3://sagemaker-us-east-1-691334595165/PMPredictiveMaintenancePipeline/prno9jsypm5c/EvaluatePMModel/output\n",
      "\n",
      "Files found in this path:\n",
      "- PMPredictiveMaintenancePipeline/prno9jsypm5c/EvaluatePMModel/output/evaluation.json\n",
      "\n",
      "Found evaluation.json at: PMPredictiveMaintenancePipeline/prno9jsypm5c/EvaluatePMModel/output/evaluation.json\n",
      "\n",
      "Processing improved model metrics:\n",
      "\n",
      "Processing execution ID: 0alha7bwdcpc\n",
      "Processing job name: pipelines-0alha7bwdcpc-EvaluatePMModel-QlLs0KLJZB\n",
      "\n",
      "Searching for evaluation.json in the following paths:\n",
      "Checking path: s3://sagemaker-us-east-1-691334595165/PMPredictiveMaintenancePipeline/0alha7bwdcpc/EvaluatePMModel/output\n",
      "No files found in this path\n",
      "Checking path: s3://sagemaker-us-east-1-691334595165/PMPredictiveMaintenancePipeline/0alha7bwdcpc/evaluation\n",
      "\n",
      "Files found in this path:\n",
      "- PMPredictiveMaintenancePipeline/0alha7bwdcpc/evaluation/evaluation.json\n",
      "\n",
      "Found evaluation.json at: PMPredictiveMaintenancePipeline/0alha7bwdcpc/evaluation/evaluation.json\n",
      "\n",
      "Model Comparison Resources:\n",
      "\n",
      "1. CloudWatch Dashboard:\n",
      "https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#dashboards:name=ModelComparison-20241026-203731\n",
      "\n",
      "2. Processing Jobs (Evaluation Results):\n",
      "Initial model: https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1#/processing-jobs/pipelines-prno9jsypm5c-EvaluatePMModel-PpOc5KWVLn\n",
      "Improved model: https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1#/processing-jobs/pipelines-0alha7bwdcpc-EvaluatePMModel-QlLs0KLJZB\n",
      "\n",
      "Metrics Comparison:\n",
      "\n",
      "Metric      Initial    Improved   Difference\n",
      "---------------------------------------------\n",
      "accuracy   0.9681    0.9717    +0.0035\n",
      "precision  0.9547    0.9512    -0.0034\n",
      "recall     0.9830    0.9943    +0.0114\n",
      "f1         0.9686    0.9723    +0.0037\n",
      "auc_roc    0.9958    0.9976    +0.0018\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    comparison = track_model_comparison(execution, improved_execution)\n",
    "except Exception as e:\n",
    "    print(f\"\\nFailed to create comparison: {str(e)}\")\n",
    "    print(\"\\nPlease check the logs above for details about where the evaluation files are located.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952057f2-32fe-4eed-af22-856636353914",
   "metadata": {},
   "source": [
    "#### Delete all pipelines on account (don't run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d0289-bd1f-4b3d-8a78-27fbca7f3f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# List all pipelines in your account\n",
    "pipelines = sagemaker_client.list_pipelines()\n",
    "\n",
    "# Loop through all pipelines and delete each one\n",
    "for pipeline in pipelines['PipelineSummaries']:\n",
    "    pipeline_name = pipeline['PipelineName']\n",
    "    print(f\"Deleting pipeline: {pipeline_name}\")\n",
    "    \n",
    "    # Delete the pipeline\n",
    "    sagemaker_client.delete_pipeline(PipelineName=pipeline_name)\n",
    "\n",
    "print(\"All pipelines deleted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c40ad-adf0-493d-bb39-e9b0950c76fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
